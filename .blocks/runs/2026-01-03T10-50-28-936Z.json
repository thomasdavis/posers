{
  "version": "1.0",
  "id": "2026-01-03T10-50-28-936Z",
  "timestamp": "2026-01-03T10:51:00.399Z",
  "configPath": "blocks.yml",
  "projectName": "Posers Motion Engine",
  "duration": 31628,
  "summary": {
    "totalBlocks": 5,
    "passed": 1,
    "failed": 2,
    "warnings": 2,
    "cached": {
      "validatorsSkipped": 0,
      "validatorsRun": 10,
      "timeSavedMs": 0
    }
  },
  "blocks": [
    {
      "blockName": "confident_stance",
      "blockPath": "/Users/ajaxdavis/repos/lisa/posers/packages/motion-dsl/src/motions/confident-stance.ts",
      "hasErrors": true,
      "hasWarnings": true,
      "validators": [
        {
          "id": "schema.io",
          "label": "schema",
          "passed": true,
          "duration": 0,
          "issues": [],
          "context": {
            "filesAnalyzed": [
              "blocks.yml"
            ],
            "rulesApplied": [
              "input_schema_complete",
              "output_schema_complete",
              "block_has_description"
            ],
            "summary": "Schema validation passed. Validated 2 input(s) and 1 output(s). All schemas are complete with name and type fields.",
            "input": {
              "blockName": "confident_stance",
              "inputs": [
                {
                  "name": "rig",
                  "type": "entity.rig"
                },
                {
                  "name": "ctx",
                  "type": "entity.motion_context"
                }
              ],
              "outputs": [
                {
                  "name": "pose",
                  "type": "entity.motion_program",
                  "constraints": [
                    "Must animate spine chain for posture",
                    "Must include subtle breathing oscillation",
                    "Must add micro-movement noise layer",
                    "Should animate fingers if available",
                    "Should animate eyes if available"
                  ]
                }
              ],
              "description": "Power pose with subtle breathing and weight shifts - uses all available bones",
              "path": "packages/motion-dsl/src/motions/confident-stance.ts"
            },
            "output": {
              "checksPerformed": [
                "Validating 2 input definition(s)",
                "  ✓ Input \"rig\" has valid schema (type: entity.rig)",
                "  ✓ Input \"ctx\" has valid schema (type: entity.motion_context)",
                "Validating 1 output definition(s)",
                "  ✓ Output \"pose\" has valid schema (type: entity.motion_program)",
                "✓ Block has description: \"Power pose with subtle breathing and weight shifts...\""
              ],
              "inputCount": 2,
              "outputCount": 1,
              "hasDescription": true
            }
          }
        },
        {
          "id": "domain.validation",
          "label": "domain",
          "passed": false,
          "duration": 9197,
          "issues": [
            {
              "type": "warning",
              "code": "DOMAIN_SEMANTIC_ISSUE",
              "message": "The structure for applying micro-movements on the head seems to lack variation in the noise application across different axes for all bone rotations. This might hinder the organic feel specified in the Blocks philosophy.",
              "file": "packages/motion-dsl/src/motions/confident-stance.ts"
            },
            {
              "type": "error",
              "code": "DOMAIN_SEMANTIC_ISSUE",
              "message": "The blink timing logic relies heavily on random noise, which could lead to non-deterministic outputs. It needs a deterministic mechanism to ensure consistent animations across multiple runs with the same seed.",
              "file": "packages/motion-dsl/src/motions/confident-stance.ts"
            },
            {
              "type": "warning",
              "code": "DOMAIN_SEMANTIC_ISSUE",
              "message": "The code handles optional bones but lacks adequate error handling or fallbacks for cases where a required bone is missing. Ensure it gracefully handles cases where bones are not available while still meeting the domain's performance criteria.",
              "file": "packages/motion-dsl/src/motions/confident-stance.ts"
            },
            {
              "type": "warning",
              "code": "DOMAIN_SEMANTIC_ISSUE",
              "message": "No functionality or logic is present to gracefully handle situations where the 'fingerMovement' or 'eyeMovement' parameters are set to false. This could lead to unexpected behavior or lack of expression in those parts when toggled off.",
              "file": "packages/motion-dsl/src/motions/confident-stance.ts"
            },
            {
              "type": "error",
              "code": "DOMAIN_SEMANTIC_ISSUE",
              "message": "The motion implementation does not clearly reflect a deterministic design as specified in the domain rules since certain noise parameters contribute to randomness. Requires more oversight to ensure consistent animations when the same parameters are input.",
              "file": "packages/motion-dsl/src/motions/confident-stance.ts"
            }
          ],
          "context": {
            "filesAnalyzed": [
              "confident-stance.ts"
            ],
            "rulesApplied": [],
            "philosophy": [
              "Motions must be anatomically accurate and biomechanically sound",
              "Every motion should utilize maximum bone engagement for realism",
              "Transitions between motions must be fluid and seamless",
              "Code must be deterministic - same seed produces same animation",
              "Movements should feel organic through layered animation and secondary motion",
              "All motions must gracefully handle missing optional bones",
              "Performance is critical - updates must complete in under 2ms",
              "Physics-based spring dynamics create natural acceleration curves",
              "Micro-movements and noise add life to static poses"
            ],
            "summary": "The block demonstrates a clear intent in its structure and usage of inputs/outputs; however, it fails validation primarily due to non-deterministic features that conflict with the Blocks philosophy. Improvement in handling optional bones and refining randomness in animation logic is necessary."
          },
          "ai": {
            "provider": "openai",
            "model": "gpt-4o-mini",
            "prompt": "Block Name: confident_stance\n\n\nBLOCKS PHILOSOPHY:\n- Motions must be anatomically accurate and biomechanically sound\n- Every motion should utilize maximum bone engagement for realism\n- Transitions between motions must be fluid and seamless\n- Code must be deterministic - same seed produces same animation\n- Movements should feel organic through layered animation and secondary motion\n- All motions must gracefully handle missing optional bones\n- Performance is critical - updates must complete in under 2ms\n- Physics-based spring dynamics create natural acceleration curves\n- Micro-movements and noise add life to static poses\n\nBlock Definition:\n{\n  \"description\": \"Power pose with subtle breathing and weight shifts - uses all available bones\",\n  \"path\": \"packages/motion-dsl/src/motions/confident-stance.ts\",\n  \"inputs\": [\n    {\n      \"name\": \"rig\",\n      \"type\": \"entity.rig\"\n    },\n    {\n      \"name\": \"ctx\",\n      \"type\": \"entity.motion_context\"\n    }\n  ],\n  \"outputs\": [\n    {\n      \"name\": \"pose\",\n      \"type\": \"entity.motion_program\",\n      \"constraints\": [\n        \"Must animate spine chain for posture\",\n        \"Must include subtle breathing oscillation\",\n        \"Must add micro-movement noise layer\",\n        \"Should animate fingers if available\",\n        \"Should animate eyes if available\"\n      ]\n    }\n  ]\n}\n\n\nBLOCK FILES:\n\n--- confident-stance.ts ---\n```\n/**\n * Confident Stance Motion\n *\n * A power pose with subtle weight distribution, commanding posture,\n * and organic micro-movements. Uses all available bones for maximum\n * realism with layered animation approach.\n *\n * Research basis:\n * - Power pose psychology (Carney et al.)\n * - Postural sway biomechanics\n * - Weight distribution patterns\n * - Breathing mechanics in standing posture\n */\n\nimport { z } from 'zod'\nimport type { MotionProgram, MotionMeta, HumanoidRig, MotionContext, VRMHumanBoneName } from '@posers/core'\nimport {\n  osc,\n  oscBreathing,\n  quatFromAxisAngle,\n  createNoiseGenerator,\n  createSpring,\n  Easing,\n  type NoiseGenerator,\n  type Spring,\n} from '@posers/core'\nimport {\n  BoneChains,\n  getAvailableBones,\n  applyFingerCurl,\n  applyFingerSpread,\n} from '../blend'\n\n// ============================================================================\n// SCHEMA & TYPES\n// ============================================================================\n\nexport const confidentStanceParamsSchema = z.object({\n  /** Overall intensity of the pose (0-1). Default: 0.7 */\n  intensity: z.number().min(0).max(1).default(0.7),\n  /** Breath rate in Hz. Default: 0.15 (slower, confident breathing) */\n  breathRate: z.number().min(0.05).max(0.5).default(0.15),\n  /** Amount of hip sway side-to-side (0-1). Default: 0.3 */\n  swayAmount: z.number().min(0).max(1).default(0.3),\n  /** Enable eye micro-movements. Default: true */\n  eyeMovement: z.boolean().default(true),\n  /** Enable finger movements. Default: true */\n  fingerMovement: z.boolean().default(true),\n  /** Weight distribution bias (-1=left, 0=center, 1=right). Default: 0.15 */\n  weightBias: z.number().min(-1).max(1).default(0.15),\n  /** Shoulder tension level (0=relaxed, 1=tense). Default: 0.2 */\n  shoulderTension: z.number().min(0).max(1).default(0.2),\n  /** Chest out amount (0-1). Default: 0.6 */\n  chestOut: z.number().min(0).max(1).default(0.6),\n  /** Chin up amount (0-1). Default: 0.3 */\n  chinUp: z.number().min(0).max(1).default(0.3),\n})\n\nexport type ConfidentStanceParams = z.infer<typeof confidentStanceParamsSchema>\nexport type ConfidentStanceInput = z.input<typeof confidentStanceParamsSchema>\n\nexport const confidentStanceMeta: MotionMeta = {\n  id: 'confident-stance',\n  name: 'Confident Stance',\n  description: 'Power pose with commanding presence, subtle breathing, and organic micro-movements',\n  tags: ['stance', 'confident', 'power', 'idle'],\n  author: 'posers',\n}\n\n// ============================================================================\n// STATE MANAGEMENT\n// ============================================================================\n\ninterface ConfidentStanceState {\n  noise: NoiseGenerator\n  weightShiftSpring: Spring\n  blinkTimer: number\n  blinkDuration: number\n  isBlinking: boolean\n  lastBlinkTime: number\n}\n\nfunction initState(seed: number): ConfidentStanceState {\n  return {\n    noise: createNoiseGenerator(seed),\n    weightShiftSpring: createSpring({ stiffness: 50, damping: 15 }),\n    blinkTimer: 0,\n    blinkDuration: 0.15,\n    isBlinking: false,\n    lastBlinkTime: 0,\n  }\n}\n\n// ============================================================================\n// MOTION IMPLEMENTATION\n// ============================================================================\n\nexport function createConfidentStance(params: ConfidentStanceInput = {}): MotionProgram<ConfidentStanceParams> {\n  const validatedParams = confidentStanceParamsSchema.parse(params)\n  let state: ConfidentStanceState | null = null\n\n  return {\n    meta: confidentStanceMeta,\n    paramsSchema: confidentStanceParamsSchema,\n\n    init(_rig: HumanoidRig, ctx: MotionContext): void {\n      state = initState(ctx.seed)\n    },\n\n    update(rig: HumanoidRig, ctx: MotionContext, t: number, dt: number): void {\n      // Lazy initialization if init wasn't called\n      if (!state) {\n        state = initState(ctx.seed)\n      }\n\n      const {\n        intensity,\n        breathRate,\n        swayAmount,\n        eyeMovement,\n        fingerMovement,\n        weightBias,\n        shoulderTension,\n        chestOut,\n        chinUp,\n      } = validatedParams\n\n      const noise = state.noise\n\n      // ========================================\n      // LAYER 1: BASE POSTURE\n      // ========================================\n\n      // Hips - slight forward tilt for confident stance\n      const hipsTilt = -0.03 * intensity // Slight posterior tilt\n      const hipsYaw = weightBias * 0.05 * intensity\n      if (rig.hasBone('hips')) {\n        const hipsRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, hipsTilt)\n        hipsRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, hipsYaw))\n        rig.setRotation('hips', hipsRot)\n      }\n\n      // Spine chain - tall, proud posture\n      const spineExtension = 0.02 * intensity * chestOut\n      if (rig.hasBone('spine')) {\n        rig.setRotation('spine', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -spineExtension * 0.5))\n      }\n      if (rig.hasBone('chest')) {\n        rig.setRotation('chest', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -spineExtension))\n      }\n      if (rig.hasBone('upperChest')) {\n        rig.setRotation('upperChest', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -spineExtension * 1.2))\n      }\n\n      // Neck and head - chin slightly up\n      const neckExtension = chinUp * 0.03 * intensity\n      if (rig.hasBone('neck')) {\n        rig.setRotation('neck', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -neckExtension * 0.5))\n      }\n      if (rig.hasBone('head')) {\n        const headRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -neckExtension)\n        rig.setRotation('head', headRot)\n      }\n\n      // Shoulders - pulled back for confident posture\n      const shoulderPullBack = 0.08 * intensity * (1 - shoulderTension * 0.5)\n      const shoulderDown = shoulderTension * 0.05 * intensity\n      if (rig.hasBone('leftShoulder')) {\n        const leftShoulderRot = quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -shoulderDown)\n        leftShoulderRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, -shoulderPullBack))\n        rig.setRotation('leftShoulder', leftShoulderRot)\n      }\n      if (rig.hasBone('rightShoulder')) {\n        const rightShoulderRot = quatFromAxisAngle({ x: 0, y: 0, z: 1 }, shoulderDown)\n        rightShoulderRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, shoulderPullBack))\n        rig.setRotation('rightShoulder', rightShoulderRot)\n      }\n\n      // Arms - relaxed at sides with slight separation\n      const armAbduction = 0.12 * intensity\n      const armRelax = 0.08 * intensity\n      if (rig.hasBone('leftUpperArm')) {\n        const leftUpperArmRot = quatFromAxisAngle({ x: 0, y: 0, z: 1 }, armAbduction)\n        leftUpperArmRot.multiply(quatFromAxisAngle({ x: 1, y: 0, z: 0 }, armRelax))\n        rig.setRotation('leftUpperArm', leftUpperArmRot)\n      }\n      if (rig.hasBone('rightUpperArm')) {\n        const rightUpperArmRot = quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -armAbduction)\n        rightUpperArmRot.multiply(quatFromAxisAngle({ x: 1, y: 0, z: 0 }, armRelax))\n        rig.setRotation('rightUpperArm', rightUpperArmRot)\n      }\n\n      // Lower arms - slightly bent\n      const elbowBend = 0.15 * intensity\n      if (rig.hasBone('leftLowerArm')) {\n        rig.setRotation('leftLowerArm', quatFromAxisAngle({ x: 0, y: 1, z: 0 }, -elbowBend))\n      }\n      if (rig.hasBone('rightLowerArm')) {\n        rig.setRotation('rightLowerArm', quatFromAxisAngle({ x: 0, y: 1, z: 0 }, elbowBend))\n      }\n\n      // Hands - natural rotation\n      const handRotation = 0.1 * intensity\n      if (rig.hasBone('leftHand')) {\n        rig.setRotation('leftHand', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, handRotation))\n      }\n      if (rig.hasBone('rightHand')) {\n        rig.setRotation('rightHand', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -handRotation))\n      }\n\n      // Legs - weight distribution\n      const standingLegBend = 0.05 * intensity\n      const relaxedLegBend = 0.12 * intensity\n      const leftWeight = weightBias < 0 ? 1 : 1 - weightBias\n      const rightWeight = weightBias > 0 ? 1 : 1 + weightBias\n\n      if (rig.hasBone('leftUpperLeg')) {\n        const leftLegRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, standingLegBend * leftWeight + relaxedLegBend * (1 - leftWeight))\n        rig.setRotation('leftUpperLeg', leftLegRot)\n      }\n      if (rig.hasBone('rightUpperLeg')) {\n        const rightLegRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, standingLegBend * rightWeight + relaxedLegBend * (1 - rightWeight))\n        rig.setRotation('rightUpperLeg', rightLegRot)\n      }\n\n      // Knee slight bend for natural stance\n      if (rig.hasBone('leftLowerLeg')) {\n        rig.setRotation('leftLowerLeg', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -0.08 * leftWeight))\n      }\n      if (rig.hasBone('rightLowerLeg')) {\n        rig.setRotation('rightLowerLeg', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -0.08 * rightWeight))\n      }\n\n      // Feet - flat with slight outward rotation\n      const footOutward = 0.1 * intensity\n      if (rig.hasBone('leftFoot')) {\n        rig.setRotation('leftFoot', quatFromAxisAngle({ x: 0, y: 1, z: 0 }, -footOutward))\n      }\n      if (rig.hasBone('rightFoot')) {\n        rig.setRotation('rightFoot', quatFromAxisAngle({ x: 0, y: 1, z: 0 }, footOutward))\n      }\n\n      // ========================================\n      // LAYER 2: BREATHING\n      // ========================================\n\n      const breathPhase = oscBreathing(t, breathRate, intensity)\n\n      // Add breathing to spine\n      if (rig.hasBone('chest')) {\n        rig.addRotation('chest', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, breathPhase * 0.015))\n      }\n      if (rig.hasBone('upperChest')) {\n        rig.addRotation('upperChest', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, breathPhase * 0.02))\n      }\n\n      // Shoulder rise with breath\n      const shoulderBreath = breathPhase * 0.008\n      if (rig.hasBone('leftShoulder')) {\n        rig.addRotation('leftShoulder', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -shoulderBreath))\n      }\n      if (rig.hasBone('rightShoulder')) {\n        rig.addRotation('rightShoulder', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, shoulderBreath))\n      }\n\n      // ========================================\n      // LAYER 3: WEIGHT SHIFT\n      // ========================================\n\n      // Slow, subtle weight shifting\n      const weightShiftTarget = noise.noise2D(t * 0.15, 0) * swayAmount * 0.5\n      state.weightShiftSpring.setTarget(weightShiftTarget)\n      state.weightShiftSpring.update(dt)\n      const currentShift = state.weightShiftSpring.value\n\n      // Apply weight shift to hips\n      if (rig.hasBone('hips')) {\n        rig.addRotation('hips', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, currentShift * 0.03))\n      }\n\n      // Counter-rotate spine\n      if (rig.hasBone('spine')) {\n        rig.addRotation('spine', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -currentShift * 0.015))\n      }\n\n      // ========================================\n      // LAYER 4: MICRO-MOVEMENTS\n      // ========================================\n\n      // Subtle noise on all joints for organic feel\n      const microIntensity = 0.003 * intensity\n\n      // Head micro-movements\n      if (rig.hasBone('head')) {\n        const headNoiseX = noise.noise2D(t * 0.3, 100) * microIntensity\n        const headNoiseY = noise.noise2D(t * 0.25, 200) * microIntensity\n        const headNoiseZ = noise.noise2D(t * 0.2, 300) * microIntensity * 0.5\n        rig.addRotation('head', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, headNoiseX))\n        rig.addRotation('head', quatFromAxisAngle({ x: 0, y: 1, z: 0 }, headNoiseY))\n        rig.addRotation('head', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, headNoiseZ))\n      }\n\n      // Upper arm micro-movements\n      if (rig.hasBone('leftUpperArm')) {\n        const armNoiseL = noise.noise2D(t * 0.2, 400) * microIntensity\n        rig.addRotation('leftUpperArm', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, armNoiseL))\n      }\n      if (rig.hasBone('rightUpperArm')) {\n        const armNoiseR = noise.noise2D(t * 0.2, 500) * microIntensity\n        rig.addRotation('rightUpperArm', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, armNoiseR))\n      }\n\n      // ========================================\n      // LAYER 5: FINGERS\n      // ========================================\n\n      if (fingerMovement) {\n        // Relaxed, slightly curled fingers\n        const baseCurl = 0.25 + noise.noise2D(t * 0.1, 600) * 0.1\n\n        // Left hand\n        applyFingerCurl(rig, 'left', {\n          thumb: baseCurl * 0.6,\n          index: baseCurl,\n          middle: baseCurl * 1.1,\n          ring: baseCurl * 1.15,\n          little: baseCurl * 1.2,\n        })\n\n        // Right hand\n        applyFingerCurl(rig, 'right', {\n          thumb: baseCurl * 0.6,\n          index: baseCurl,\n          middle: baseCurl * 1.1,\n          ring: baseCurl * 1.15,\n          little: baseCurl * 1.2,\n        })\n\n        // Slight finger spread\n        applyFingerSpread(rig, 'left', 0.2)\n        applyFingerSpread(rig, 'right', 0.2)\n      }\n\n      // ========================================\n      // LAYER 6: EYES\n      // ========================================\n\n      if (eyeMovement) {\n        // Slow, deliberate eye movement\n        const eyeSpeed = 0.15\n        const eyeX = noise.noise2D(t * eyeSpeed, 700) * 0.04 * intensity\n        const eyeY = noise.noise2D(t * eyeSpeed, 800) * 0.03 * intensity\n\n        // Blinking\n        const timeSinceLastBlink = t - state.lastBlinkTime\n        const blinkInterval = 3 + noise.noise2D(t * 0.05, 900) * 2\n        if (timeSinceLastBlink > blinkInterval && !state.isBlinking) {\n          state.isBlinking = true\n          state.blinkTimer = 0\n        }\n\n        let blinkAmount = 0\n        if (state.isBlinking) {\n          state.blinkTimer += dt\n          const blinkProgress = state.blinkTimer / state.blinkDuration\n          if (blinkProgress >= 1) {\n            state.isBlinking = false\n            state.lastBlinkTime = t\n          } else {\n            // Quick close, slower open\n            blinkAmount = blinkProgress < 0.3\n              ? Easing.easeOutQuad(blinkProgress / 0.3)\n              : Easing.easeInQuad(1 - (blinkProgress - 0.3) / 0.7)\n          }\n        }\n\n        // Apply eye rotations\n        if (rig.hasBone('leftEye')) {\n          const leftEyeRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, eyeY - blinkAmount * 0.3)\n          leftEyeRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, eyeX))\n          rig.setRotation('leftEye', leftEyeRot)\n        }\n        if (rig.hasBone('rightEye')) {\n          const rightEyeRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, eyeY - blinkAmount * 0.3)\n          rightEyeRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, eyeX))\n          rig.setRotation('rightEye', rightEyeRot)\n        }\n      }\n\n      // ========================================\n      // LAYER 7: TOES\n      // ========================================\n\n      // Toes slightly gripping for balance\n      if (rig.hasBone('leftToes')) {\n        rig.setRotation('leftToes', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, 0.1 * leftWeight))\n      }\n      if (rig.hasBone('rightToes')) {\n        rig.setRotation('rightToes', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, 0.1 * rightWeight))\n      }\n    },\n  }\n}\n\nexport const confidentStance: MotionProgram<ConfidentStanceParams> = createConfidentStance({})\n\n```\n\n\nVALIDATION TASK:\nAnalyze ALL files together to determine if this block:\n1. Expresses domain intent clearly in source code\n2. Uses specified inputs/outputs correctly\n3. Adheres to all domain rules\n4. For templates: Check if template SOURCE contains semantic HTML, ARIA labels, media queries, heading hierarchy\n5. Does NOT introduce undocumented concepts\n\nReturn validation issues with specific file references where possible.\nAlso provide a brief summary explaining why the block passed or failed validation.",
            "response": "{\n  \"isValid\": false,\n  \"issues\": [\n    {\n      \"message\": \"The structure for applying micro-movements on the head seems to lack variation in the noise application across different axes for all bone rotations. This might hinder the organic feel specified in the Blocks philosophy.\",\n      \"severity\": \"warning\",\n      \"file\": \"packages/motion-dsl/src/motions/confident-stance.ts\"\n    },\n    {\n      \"message\": \"The blink timing logic relies heavily on random noise, which could lead to non-deterministic outputs. It needs a deterministic mechanism to ensure consistent animations across multiple runs with the same seed.\",\n      \"severity\": \"error\",\n      \"file\": \"packages/motion-dsl/src/motions/confident-stance.ts\"\n    },\n    {\n      \"message\": \"The code handles optional bones but lacks adequate error handling or fallbacks for cases where a required bone is missing. Ensure it gracefully handles cases where bones are not available while still meeting the domain's performance criteria.\",\n      \"severity\": \"warning\",\n      \"file\": \"packages/motion-dsl/src/motions/confident-stance.ts\"\n    },\n    {\n      \"message\": \"No functionality or logic is present to gracefully handle situations where the 'fingerMovement' or 'eyeMovement' parameters are set to false. This could lead to unexpected behavior or lack of expression in those parts when toggled off.\",\n      \"severity\": \"warning\",\n      \"file\": \"packages/motion-dsl/src/motions/confident-stance.ts\"\n    },\n    {\n      \"message\": \"The motion implementation does not clearly reflect a deterministic design as specified in the domain rules since certain noise parameters contribute to randomness. Requires more oversight to ensure consistent animations when the same parameters are input.\",\n      \"severity\": \"error\",\n      \"file\": \"packages/motion-dsl/src/motions/confident-stance.ts\"\n    }\n  ],\n  \"summary\": \"The block demonstrates a clear intent in its structure and usage of inputs/outputs; however, it fails validation primarily due to non-deterministic features that conflict with the Blocks philosophy. Improvement in handling optional bones and refining randomness in animation logic is necessary.\"\n}",
            "tokensUsed": {
              "input": 5021,
              "output": 374
            }
          }
        }
      ],
      "cache": {
        "decision": "Force mode: running all validators",
        "skippedValidators": 0,
        "revalidationReason": "force_flag"
      }
    },
    {
      "blockName": "nervous_fidget",
      "blockPath": "/Users/ajaxdavis/repos/lisa/posers/packages/motion-dsl/src/motions/nervous-fidget.ts",
      "hasErrors": false,
      "hasWarnings": true,
      "validators": [
        {
          "id": "schema.io",
          "label": "schema",
          "passed": true,
          "duration": 0,
          "issues": [],
          "context": {
            "filesAnalyzed": [
              "blocks.yml"
            ],
            "rulesApplied": [
              "input_schema_complete",
              "output_schema_complete",
              "block_has_description"
            ],
            "summary": "Schema validation passed. Validated 2 input(s) and 1 output(s). All schemas are complete with name and type fields.",
            "input": {
              "blockName": "nervous_fidget",
              "inputs": [
                {
                  "name": "rig",
                  "type": "entity.rig"
                },
                {
                  "name": "ctx",
                  "type": "entity.motion_context"
                }
              ],
              "outputs": [
                {
                  "name": "pose",
                  "type": "entity.motion_program",
                  "constraints": [
                    "Must show tension in shoulders and neck",
                    "Must include irregular weight shifting",
                    "Must animate hands/fingers for fidgeting",
                    "Should include rapid eye movement if available",
                    "Breathing should be shallow and faster"
                  ]
                }
              ],
              "description": "Anxiety-driven fidgeting with weight shifts and self-soothing gestures",
              "path": "packages/motion-dsl/src/motions/nervous-fidget.ts"
            },
            "output": {
              "checksPerformed": [
                "Validating 2 input definition(s)",
                "  ✓ Input \"rig\" has valid schema (type: entity.rig)",
                "  ✓ Input \"ctx\" has valid schema (type: entity.motion_context)",
                "Validating 1 output definition(s)",
                "  ✓ Output \"pose\" has valid schema (type: entity.motion_program)",
                "✓ Block has description: \"Anxiety-driven fidgeting with weight shifts and se...\""
              ],
              "inputCount": 2,
              "outputCount": 1,
              "hasDescription": true
            }
          }
        },
        {
          "id": "domain.validation",
          "label": "domain",
          "passed": true,
          "duration": 7868,
          "issues": [
            {
              "type": "warning",
              "code": "DOMAIN_SEMANTIC_ISSUE",
              "message": "The motion logic does not clearly reflect biomechanical accuracy and anatomically sound motions, particularly in rapid transitions between nerve fidget motions and the lack of fluidity in some arm movements.",
              "file": "packages/motion-dsl/src/motions/nervous-fidget.ts"
            },
            {
              "type": "warning",
              "code": "DOMAIN_SEMANTIC_ISSUE",
              "message": "The handling of optional bones (e.g., 'head', 'neck', etc.) is not consistent; while some operations have checks for existence, others assume the presence of bones without safety checks leading to potential runtime errors.",
              "file": "packages/motion-dsl/src/motions/nervous-fidget.ts"
            },
            {
              "type": "warning",
              "code": "DOMAIN_SEMANTIC_ISSUE",
              "message": "The performance requirement of under 2ms could be at risk due to the usage of multiple noise generators and the complexity of the motion calculations performed within the update function, potentially leading to performance issues.",
              "file": "packages/motion-dsl/src/motions/nervous-fidget.ts"
            },
            {
              "type": "warning",
              "code": "DOMAIN_SEMANTIC_ISSUE",
              "message": "The fidgeting mechanism must incorporate maximum bone engagement for realism; while it attempts to simulate fidgeting, it lacks full engagement of the necessary bones for a realistic portrayal of anxiety-driven behavior.",
              "file": "packages/motion-dsl/src/motions/nervous-fidget.ts"
            }
          ],
          "context": {
            "filesAnalyzed": [
              "nervous-fidget.ts"
            ],
            "rulesApplied": [],
            "philosophy": [
              "Motions must be anatomically accurate and biomechanically sound",
              "Every motion should utilize maximum bone engagement for realism",
              "Transitions between motions must be fluid and seamless",
              "Code must be deterministic - same seed produces same animation",
              "Movements should feel organic through layered animation and secondary motion",
              "All motions must gracefully handle missing optional bones",
              "Performance is critical - updates must complete in under 2ms",
              "Physics-based spring dynamics create natural acceleration curves",
              "Micro-movements and noise add life to static poses"
            ],
            "summary": "The block fails validation primarily due to issues with biomechanical accuracy, inconsistent handling of optional bones, potential performance overhead, and insufficient engagement of bones during fidgeting motions. While the code attempts to express anxiety-driven fidgeting behavior, it lacks some of the domain requirements outlined in the Blocks philosophy."
          },
          "ai": {
            "provider": "openai",
            "model": "gpt-4o-mini",
            "prompt": "Block Name: nervous_fidget\n\n\nBLOCKS PHILOSOPHY:\n- Motions must be anatomically accurate and biomechanically sound\n- Every motion should utilize maximum bone engagement for realism\n- Transitions between motions must be fluid and seamless\n- Code must be deterministic - same seed produces same animation\n- Movements should feel organic through layered animation and secondary motion\n- All motions must gracefully handle missing optional bones\n- Performance is critical - updates must complete in under 2ms\n- Physics-based spring dynamics create natural acceleration curves\n- Micro-movements and noise add life to static poses\n\nBlock Definition:\n{\n  \"description\": \"Anxiety-driven fidgeting with weight shifts and self-soothing gestures\",\n  \"path\": \"packages/motion-dsl/src/motions/nervous-fidget.ts\",\n  \"inputs\": [\n    {\n      \"name\": \"rig\",\n      \"type\": \"entity.rig\"\n    },\n    {\n      \"name\": \"ctx\",\n      \"type\": \"entity.motion_context\"\n    }\n  ],\n  \"outputs\": [\n    {\n      \"name\": \"pose\",\n      \"type\": \"entity.motion_program\",\n      \"constraints\": [\n        \"Must show tension in shoulders and neck\",\n        \"Must include irregular weight shifting\",\n        \"Must animate hands/fingers for fidgeting\",\n        \"Should include rapid eye movement if available\",\n        \"Breathing should be shallow and faster\"\n      ]\n    }\n  ]\n}\n\n\nBLOCK FILES:\n\n--- nervous-fidget.ts ---\n```\n/**\n * Nervous Fidget Motion\n *\n * Anxiety-driven motion with rapid weight shifts, self-soothing gestures,\n * and tense posture. Captures the biomechanics of nervousness and\n * displacement behavior.\n *\n * Research basis:\n * - Anxiety body language (Navarro)\n * - Self-soothing behaviors (pacifying gestures)\n * - Displacement activities in stress\n * - Hypervigilance postural patterns\n */\n\nimport { z } from 'zod'\nimport type { MotionProgram, MotionMeta, HumanoidRig, MotionContext, VRMHumanBoneName } from '@posers/core'\nimport {\n  osc,\n  quatFromAxisAngle,\n  createNoiseGenerator,\n  createSpring,\n  Easing,\n  type NoiseGenerator,\n  type Spring,\n} from '@posers/core'\nimport {\n  BoneChains,\n  getAvailableBones,\n  applyFingerCurl,\n} from '../blend'\n\n// ============================================================================\n// SCHEMA & TYPES\n// ============================================================================\n\nexport const nervousFidgetParamsSchema = z.object({\n  /** Overall anxiety level (0-1). Default: 0.6 */\n  anxietyLevel: z.number().min(0).max(1).default(0.6),\n  /** Intensity of fidgeting movements (0-1). Default: 0.5 */\n  fidgetIntensity: z.number().min(0).max(1).default(0.5),\n  /** Speed of looking around (0-1). Default: 0.4 */\n  lookAroundSpeed: z.number().min(0).max(1).default(0.4),\n  /** Breath rate multiplier (nervous = faster). Default: 1.5 */\n  breathRateMultiplier: z.number().min(1).max(3).default(1.5),\n  /** Enable hand fidgeting. Default: true */\n  handFidget: z.boolean().default(true),\n  /** Enable foot tapping. Default: true */\n  footTap: z.boolean().default(true),\n  /** Enable rapid eye movement. Default: true */\n  rapidEyeMovement: z.boolean().default(true),\n  /** Shoulder tension (0-1). Default: 0.7 */\n  shoulderTension: z.number().min(0).max(1).default(0.7),\n})\n\nexport type NervousFidgetParams = z.infer<typeof nervousFidgetParamsSchema>\nexport type NervousFidgetInput = z.input<typeof nervousFidgetParamsSchema>\n\nexport const nervousFidgetMeta: MotionMeta = {\n  id: 'nervous-fidget',\n  name: 'Nervous Fidget',\n  description: 'Anxiety-driven fidgeting with weight shifts, tense posture, and self-soothing gestures',\n  tags: ['nervous', 'anxiety', 'fidget', 'tension'],\n  author: 'posers',\n}\n\n// ============================================================================\n// STATE MANAGEMENT\n// ============================================================================\n\ninterface NervousFidgetState {\n  noise: NoiseGenerator\n  weightSpring: Spring\n  headSpring: Spring\n  armSpring: Spring\n  fidgetTimer: number\n  fidgetType: 'none' | 'hand_rub' | 'arm_touch' | 'neck_touch'\n  fidgetHand: 'left' | 'right'\n  lastFidgetTime: number\n  blinkTimer: number\n  isBlinking: boolean\n  footTapPhase: number\n  footTapActive: boolean\n  lookTarget: { x: number; y: number }\n  lookChangeTimer: number\n}\n\nfunction initState(seed: number): NervousFidgetState {\n  return {\n    noise: createNoiseGenerator(seed),\n    weightSpring: createSpring({ stiffness: 150, damping: 12 }),\n    headSpring: createSpring({ stiffness: 200, damping: 18 }),\n    armSpring: createSpring({ stiffness: 100, damping: 15 }),\n    fidgetTimer: 0,\n    fidgetType: 'none',\n    fidgetHand: 'right',\n    lastFidgetTime: 0,\n    blinkTimer: 0,\n    isBlinking: false,\n    footTapPhase: 0,\n    footTapActive: false,\n    lookTarget: { x: 0, y: 0 },\n    lookChangeTimer: 0,\n  }\n}\n\n// ============================================================================\n// MOTION IMPLEMENTATION\n// ============================================================================\n\nexport function createNervousFidget(params: NervousFidgetInput = {}): MotionProgram<NervousFidgetParams> {\n  const validatedParams = nervousFidgetParamsSchema.parse(params)\n  let state: NervousFidgetState | null = null\n\n  return {\n    meta: nervousFidgetMeta,\n    paramsSchema: nervousFidgetParamsSchema,\n\n    init(_rig: HumanoidRig, ctx: MotionContext): void {\n      state = initState(ctx.seed)\n    },\n\n    update(rig: HumanoidRig, ctx: MotionContext, t: number, dt: number): void {\n      if (!state) {\n        state = initState(ctx.seed)\n      }\n\n      const {\n        anxietyLevel,\n        fidgetIntensity,\n        lookAroundSpeed,\n        breathRateMultiplier,\n        handFidget,\n        footTap,\n        rapidEyeMovement,\n        shoulderTension,\n      } = validatedParams\n\n      const noise = state.noise\n      const anxiety = anxietyLevel\n\n      // ========================================\n      // LAYER 1: TENSE BASE POSTURE\n      // ========================================\n\n      // Hunched, protective stance\n      const hunch = 0.05 * anxiety\n      const forwardLean = 0.03 * anxiety\n\n      // Hips - slightly tucked\n      if (rig.hasBone('hips')) {\n        const hipsRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, forwardLean)\n        rig.setRotation('hips', hipsRot)\n      }\n\n      // Spine - forward hunch\n      if (rig.hasBone('spine')) {\n        rig.setRotation('spine', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, hunch))\n      }\n      if (rig.hasBone('chest')) {\n        rig.setRotation('chest', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, hunch * 0.8))\n      }\n      if (rig.hasBone('upperChest')) {\n        rig.setRotation('upperChest', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, hunch * 0.5))\n      }\n\n      // Shoulders - raised and tense\n      const shoulderRaise = shoulderTension * 0.08\n      const shoulderForward = shoulderTension * 0.06\n      if (rig.hasBone('leftShoulder')) {\n        const leftShoulderRot = quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -shoulderRaise)\n        leftShoulderRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, -shoulderForward))\n        rig.setRotation('leftShoulder', leftShoulderRot)\n      }\n      if (rig.hasBone('rightShoulder')) {\n        const rightShoulderRot = quatFromAxisAngle({ x: 0, y: 0, z: 1 }, shoulderRaise)\n        rightShoulderRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, shoulderForward))\n        rig.setRotation('rightShoulder', rightShoulderRot)\n      }\n\n      // Neck - forward head posture (hypervigilance)\n      if (rig.hasBone('neck')) {\n        rig.setRotation('neck', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, 0.08 * anxiety))\n      }\n\n      // Arms - held closer to body\n      const armProtect = 0.05 * anxiety\n      if (rig.hasBone('leftUpperArm')) {\n        const leftArmRot = quatFromAxisAngle({ x: 0, y: 0, z: 1 }, 0.15 - armProtect)\n        leftArmRot.multiply(quatFromAxisAngle({ x: 1, y: 0, z: 0 }, 0.1))\n        rig.setRotation('leftUpperArm', leftArmRot)\n      }\n      if (rig.hasBone('rightUpperArm')) {\n        const rightArmRot = quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -0.15 + armProtect)\n        rightArmRot.multiply(quatFromAxisAngle({ x: 1, y: 0, z: 0 }, 0.1))\n        rig.setRotation('rightUpperArm', rightArmRot)\n      }\n\n      // Bent elbows\n      if (rig.hasBone('leftLowerArm')) {\n        rig.setRotation('leftLowerArm', quatFromAxisAngle({ x: 0, y: 1, z: 0 }, -0.4 * anxiety))\n      }\n      if (rig.hasBone('rightLowerArm')) {\n        rig.setRotation('rightLowerArm', quatFromAxisAngle({ x: 0, y: 1, z: 0 }, 0.4 * anxiety))\n      }\n\n      // Legs - weight on one leg, ready to move\n      if (rig.hasBone('leftUpperLeg')) {\n        rig.setRotation('leftUpperLeg', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, 0.03))\n      }\n      if (rig.hasBone('rightUpperLeg')) {\n        rig.setRotation('rightUpperLeg', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, 0.05))\n      }\n\n      // ========================================\n      // LAYER 2: SHALLOW BREATHING\n      // ========================================\n\n      const breathRate = 0.25 * breathRateMultiplier\n      const breathPhase = Math.sin(t * breathRate * Math.PI * 2)\n      const shallowBreath = breathPhase * 0.015 * anxiety\n\n      if (rig.hasBone('chest')) {\n        rig.addRotation('chest', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, shallowBreath))\n      }\n      if (rig.hasBone('upperChest')) {\n        rig.addRotation('upperChest', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, shallowBreath * 1.2))\n      }\n\n      // Shoulder rise with anxious breath\n      const anxiousShoulderBreath = breathPhase * 0.01 * anxiety\n      if (rig.hasBone('leftShoulder')) {\n        rig.addRotation('leftShoulder', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -anxiousShoulderBreath))\n      }\n      if (rig.hasBone('rightShoulder')) {\n        rig.addRotation('rightShoulder', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, anxiousShoulderBreath))\n      }\n\n      // ========================================\n      // LAYER 3: IRREGULAR WEIGHT SHIFTING\n      // ========================================\n\n      // Quick, irregular weight shifts\n      const weightShiftNoise = noise.turbulence(t * 0.8, 0) * 2 - 1\n      const weightJitter = noise.noise2D(t * 3, 100) * fidgetIntensity * 0.3\n      state.weightSpring.setTarget(weightShiftNoise * 0.5 + weightJitter)\n      state.weightSpring.update(dt)\n      const weightShift = state.weightSpring.value * fidgetIntensity\n\n      if (rig.hasBone('hips')) {\n        rig.addRotation('hips', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, weightShift * 0.04))\n        rig.addRotation('hips', quatFromAxisAngle({ x: 0, y: 1, z: 0 }, weightShift * 0.02))\n      }\n\n      // Counter in spine\n      if (rig.hasBone('spine')) {\n        rig.addRotation('spine', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -weightShift * 0.02))\n      }\n\n      // ========================================\n      // LAYER 4: HEAD MOVEMENT (LOOKING AROUND)\n      // ========================================\n\n      // Quick, darting looks\n      state.lookChangeTimer += dt\n      const lookChangeInterval = 1.5 - lookAroundSpeed * 1.2\n      if (state.lookChangeTimer > lookChangeInterval) {\n        state.lookChangeTimer = 0\n        state.lookTarget = {\n          x: (noise.noise2D(t, 200) * 2 - 1) * 0.15 * lookAroundSpeed,\n          y: (noise.noise2D(t, 300) * 2 - 1) * 0.1 * lookAroundSpeed,\n        }\n      }\n\n      state.headSpring.setTarget(state.lookTarget.x)\n      state.headSpring.update(dt)\n      const headYaw = state.headSpring.value\n\n      // Add nervous micro-movements\n      const headJitterX = noise.noise2D(t * 4, 400) * 0.02 * fidgetIntensity\n      const headJitterY = noise.noise2D(t * 4, 500) * 0.015 * fidgetIntensity\n\n      if (rig.hasBone('head')) {\n        const headRot = quatFromAxisAngle({ x: 0, y: 1, z: 0 }, headYaw + headJitterY)\n        headRot.multiply(quatFromAxisAngle({ x: 1, y: 0, z: 0 }, state.lookTarget.y + headJitterX))\n        rig.setRotation('head', headRot)\n      }\n\n      if (rig.hasBone('neck')) {\n        rig.addRotation('neck', quatFromAxisAngle({ x: 0, y: 1, z: 0 }, headYaw * 0.3))\n      }\n\n      // ========================================\n      // LAYER 5: HAND FIDGETING\n      // ========================================\n\n      if (handFidget) {\n        // Decide on fidget type\n        const timeSinceFidget = t - state.lastFidgetTime\n        const fidgetInterval = 2 + noise.noise2D(t * 0.1, 600) * 2\n\n        if (state.fidgetType === 'none' && timeSinceFidget > fidgetInterval) {\n          const fidgetRoll = noise.noise2D(t, 700)\n          if (fidgetRoll > 0.6) {\n            state.fidgetType = 'hand_rub'\n          } else if (fidgetRoll > 0.3) {\n            state.fidgetType = 'arm_touch'\n          } else {\n            state.fidgetType = 'neck_touch'\n          }\n          state.fidgetHand = noise.noise2D(t, 800) > 0.5 ? 'left' : 'right'\n          state.fidgetTimer = 0\n        }\n\n        if (state.fidgetType !== 'none') {\n          state.fidgetTimer += dt\n          const fidgetDuration = 1.5 + noise.noise2D(t * 0.2, 900) * 1\n          const fidgetProgress = state.fidgetTimer / fidgetDuration\n\n          if (fidgetProgress >= 1) {\n            state.fidgetType = 'none'\n            state.lastFidgetTime = t\n          } else {\n            // Ease in and out of fidget\n            const fidgetWeight = Math.sin(fidgetProgress * Math.PI)\n\n            // Apply fidget based on type\n            switch (state.fidgetType) {\n              case 'hand_rub':\n                // Bring hands together in front\n                if (rig.hasBone('leftUpperArm')) {\n                  rig.addRotation('leftUpperArm', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, 0.3 * fidgetWeight))\n                  rig.addRotation('leftUpperArm', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -0.2 * fidgetWeight))\n                }\n                if (rig.hasBone('rightUpperArm')) {\n                  rig.addRotation('rightUpperArm', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, 0.3 * fidgetWeight))\n                  rig.addRotation('rightUpperArm', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, 0.2 * fidgetWeight))\n                }\n                if (rig.hasBone('leftLowerArm')) {\n                  rig.addRotation('leftLowerArm', quatFromAxisAngle({ x: 0, y: 1, z: 0 }, -0.5 * fidgetWeight))\n                }\n                if (rig.hasBone('rightLowerArm')) {\n                  rig.addRotation('rightLowerArm', quatFromAxisAngle({ x: 0, y: 1, z: 0 }, 0.5 * fidgetWeight))\n                }\n                // Rubbing motion\n                const rubPhase = Math.sin(state.fidgetTimer * 8) * fidgetWeight\n                if (rig.hasBone('leftHand')) {\n                  rig.addRotation('leftHand', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, rubPhase * 0.2))\n                }\n                break\n\n              case 'arm_touch':\n                // Touch opposite arm\n                const touchArm = state.fidgetHand === 'left' ? 'left' : 'right'\n                if (rig.hasBone(`${touchArm}UpperArm` as VRMHumanBoneName)) {\n                  rig.addRotation(`${touchArm}UpperArm` as VRMHumanBoneName,\n                    quatFromAxisAngle({ x: 1, y: 0, z: 0 }, 0.4 * fidgetWeight))\n                }\n                if (rig.hasBone(`${touchArm}LowerArm` as VRMHumanBoneName)) {\n                  rig.addRotation(`${touchArm}LowerArm` as VRMHumanBoneName,\n                    quatFromAxisAngle({ x: 0, y: 1, z: 0 }, (touchArm === 'left' ? -1 : 1) * 0.8 * fidgetWeight))\n                }\n                break\n\n              case 'neck_touch':\n                // Touch back of neck\n                const neckArm = state.fidgetHand\n                if (rig.hasBone(`${neckArm}UpperArm` as VRMHumanBoneName)) {\n                  rig.addRotation(`${neckArm}UpperArm` as VRMHumanBoneName,\n                    quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -0.5 * fidgetWeight))\n                  rig.addRotation(`${neckArm}UpperArm` as VRMHumanBoneName,\n                    quatFromAxisAngle({ x: 0, y: 0, z: 1 }, (neckArm === 'left' ? -1 : 1) * 0.3 * fidgetWeight))\n                }\n                if (rig.hasBone(`${neckArm}LowerArm` as VRMHumanBoneName)) {\n                  rig.addRotation(`${neckArm}LowerArm` as VRMHumanBoneName,\n                    quatFromAxisAngle({ x: 0, y: 1, z: 0 }, (neckArm === 'left' ? -1 : 1) * 1.2 * fidgetWeight))\n                }\n                break\n            }\n          }\n        }\n\n        // Fingers - tense, curled\n        const fingerTension = 0.4 + noise.noise2D(t * 2, 1000) * 0.2\n        applyFingerCurl(rig, 'left', {\n          thumb: fingerTension * 0.5,\n          index: fingerTension,\n          middle: fingerTension * 1.1,\n          ring: fingerTension * 1.15,\n          little: fingerTension * 1.2,\n        })\n        applyFingerCurl(rig, 'right', {\n          thumb: fingerTension * 0.5,\n          index: fingerTension,\n          middle: fingerTension * 1.1,\n          ring: fingerTension * 1.15,\n          little: fingerTension * 1.2,\n        })\n      }\n\n      // ========================================\n      // LAYER 6: FOOT TAPPING\n      // ========================================\n\n      if (footTap) {\n        // Decide when to tap\n        const tapTrigger = noise.noise2D(t * 0.5, 1100)\n        if (!state.footTapActive && tapTrigger > 0.7) {\n          state.footTapActive = true\n          state.footTapPhase = 0\n        }\n\n        if (state.footTapActive) {\n          state.footTapPhase += dt * 6 // Fast tapping\n          const tapCycle = Math.sin(state.footTapPhase * Math.PI * 2)\n          const tapUp = Math.max(0, tapCycle) * fidgetIntensity\n\n          // Right foot tap\n          if (rig.hasBone('rightFoot')) {\n            rig.addRotation('rightFoot', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, tapUp * 0.15))\n          }\n          if (rig.hasBone('rightToes')) {\n            rig.setRotation('rightToes', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -tapUp * 0.2))\n          }\n\n          // Stop after a few taps\n          if (state.footTapPhase > 8) {\n            state.footTapActive = false\n          }\n        }\n      }\n\n      // ========================================\n      // LAYER 7: RAPID EYE MOVEMENT\n      // ========================================\n\n      if (rapidEyeMovement) {\n        // Quick, darting eye movements\n        const eyeSpeed = 3 + lookAroundSpeed * 4\n        const eyeX = noise.noise2D(t * eyeSpeed, 1200) * 0.08 * anxiety\n        const eyeY = noise.noise2D(t * eyeSpeed, 1300) * 0.06 * anxiety\n\n        // Frequent blinking\n        const blinkInterval = 1.5 - anxiety * 0.8\n        if (!state.isBlinking && noise.noise2D(t * 0.5, 1400) > 0.8) {\n          state.isBlinking = true\n          state.blinkTimer = 0\n        }\n\n        let blinkAmount = 0\n        if (state.isBlinking) {\n          state.blinkTimer += dt\n          if (state.blinkTimer > 0.12) {\n            state.isBlinking = false\n          } else {\n            blinkAmount = Math.sin(state.blinkTimer / 0.12 * Math.PI)\n          }\n        }\n\n        if (rig.hasBone('leftEye')) {\n          const leftEyeRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, eyeY - blinkAmount * 0.3)\n          leftEyeRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, eyeX))\n          rig.setRotation('leftEye', leftEyeRot)\n        }\n        if (rig.hasBone('rightEye')) {\n          const rightEyeRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, eyeY - blinkAmount * 0.3)\n          rightEyeRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, eyeX))\n          rig.setRotation('rightEye', rightEyeRot)\n        }\n      }\n\n      // ========================================\n      // LAYER 8: JAW TENSION\n      // ========================================\n\n      if (rig.hasBone('jaw')) {\n        // Slight jaw clench with occasional release\n        const jawTension = anxiety * 0.02\n        const jawRelease = noise.noise2D(t * 0.3, 1500) > 0.8 ? 0.01 : 0\n        rig.setRotation('jaw', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, jawRelease - jawTension))\n      }\n    },\n  }\n}\n\nexport const nervousFidget: MotionProgram<NervousFidgetParams> = createNervousFidget({})\n\n```\n\n\nVALIDATION TASK:\nAnalyze ALL files together to determine if this block:\n1. Expresses domain intent clearly in source code\n2. Uses specified inputs/outputs correctly\n3. Adheres to all domain rules\n4. For templates: Check if template SOURCE contains semantic HTML, ARIA labels, media queries, heading hierarchy\n5. Does NOT introduce undocumented concepts\n\nReturn validation issues with specific file references where possible.\nAlso provide a brief summary explaining why the block passed or failed validation.",
            "response": "{\n  \"isValid\": false,\n  \"issues\": [\n    {\n      \"message\": \"The motion logic does not clearly reflect biomechanical accuracy and anatomically sound motions, particularly in rapid transitions between nerve fidget motions and the lack of fluidity in some arm movements.\",\n      \"severity\": \"warning\",\n      \"file\": \"packages/motion-dsl/src/motions/nervous-fidget.ts\"\n    },\n    {\n      \"message\": \"The handling of optional bones (e.g., 'head', 'neck', etc.) is not consistent; while some operations have checks for existence, others assume the presence of bones without safety checks leading to potential runtime errors.\",\n      \"severity\": \"warning\",\n      \"file\": \"packages/motion-dsl/src/motions/nervous-fidget.ts\"\n    },\n    {\n      \"message\": \"The performance requirement of under 2ms could be at risk due to the usage of multiple noise generators and the complexity of the motion calculations performed within the update function, potentially leading to performance issues.\",\n      \"severity\": \"warning\",\n      \"file\": \"packages/motion-dsl/src/motions/nervous-fidget.ts\"\n    },\n    {\n      \"message\": \"The fidgeting mechanism must incorporate maximum bone engagement for realism; while it attempts to simulate fidgeting, it lacks full engagement of the necessary bones for a realistic portrayal of anxiety-driven behavior.\",\n      \"severity\": \"warning\",\n      \"file\": \"packages/motion-dsl/src/motions/nervous-fidget.ts\"\n    }\n  ],\n  \"summary\": \"The block fails validation primarily due to issues with biomechanical accuracy, inconsistent handling of optional bones, potential performance overhead, and insufficient engagement of bones during fidgeting motions. While the code attempts to express anxiety-driven fidgeting behavior, it lacks some of the domain requirements outlined in the Blocks philosophy.\"\n}",
            "tokensUsed": {
              "input": 5980,
              "output": 324
            }
          }
        }
      ],
      "cache": {
        "decision": "Force mode: running all validators",
        "skippedValidators": 0,
        "revalidationReason": "force_flag"
      }
    },
    {
      "blockName": "smoking_cigarette",
      "blockPath": "/Users/ajaxdavis/repos/lisa/posers/packages/motion-dsl/src/motions/smoking-cigarette.ts",
      "hasErrors": true,
      "hasWarnings": true,
      "validators": [
        {
          "id": "schema.io",
          "label": "schema",
          "passed": true,
          "duration": 0,
          "issues": [],
          "context": {
            "filesAnalyzed": [
              "blocks.yml"
            ],
            "rulesApplied": [
              "input_schema_complete",
              "output_schema_complete",
              "block_has_description"
            ],
            "summary": "Schema validation passed. Validated 2 input(s) and 1 output(s). All schemas are complete with name and type fields.",
            "input": {
              "blockName": "smoking_cigarette",
              "inputs": [
                {
                  "name": "rig",
                  "type": "entity.rig"
                },
                {
                  "name": "ctx",
                  "type": "entity.motion_context"
                }
              ],
              "outputs": [
                {
                  "name": "pose",
                  "type": "entity.motion_program",
                  "constraints": [
                    "Must implement state machine: idle, bring_to_mouth, inhale, hold, exhale, lower, ash_tap",
                    "Must use precise finger positioning for cigarette grip",
                    "Must coordinate breathing with inhale/exhale phases",
                    "Must use spring physics for arm movement",
                    "Must include secondary motion on fingers",
                    "Should squint eyes during inhale if available",
                    "Should animate jaw during exhale if available"
                  ]
                }
              ],
              "description": "Complete smoking animation with hand-to-mouth, inhale, exhale phases",
              "path": "packages/motion-dsl/src/motions/smoking-cigarette.ts"
            },
            "output": {
              "checksPerformed": [
                "Validating 2 input definition(s)",
                "  ✓ Input \"rig\" has valid schema (type: entity.rig)",
                "  ✓ Input \"ctx\" has valid schema (type: entity.motion_context)",
                "Validating 1 output definition(s)",
                "  ✓ Output \"pose\" has valid schema (type: entity.motion_program)",
                "✓ Block has description: \"Complete smoking animation with hand-to-mouth, inh...\""
              ],
              "inputCount": 2,
              "outputCount": 1,
              "hasDescription": true
            }
          }
        },
        {
          "id": "domain.validation",
          "label": "domain",
          "passed": false,
          "duration": 7614,
          "issues": [
            {
              "type": "warning",
              "code": "DOMAIN_SEMANTIC_ISSUE",
              "message": "The state machine lacks clear implementation of the 'ash_tap' state in terms of animation transitions, which may lead to non-deterministic behavior during the animation sequence.",
              "file": "packages/motion-dsl/src/motions/smoking-cigarette.ts"
            },
            {
              "type": "warning",
              "code": "DOMAIN_SEMANTIC_ISSUE",
              "message": "The use of `handedness` and its effect on the animation is not fully accounted for in transition logic (e.g., different animations for left vs right hand) which can cause ambiguity in animations for left-handed users.",
              "file": "packages/motion-dsl/src/motions/smoking-cigarette.ts"
            },
            {
              "type": "warning",
              "code": "DOMAIN_SEMANTIC_ISSUE",
              "message": "Certain parameters like `intensity` do not clearly quantify their influence on the animation, leading to potential inconsistencies in motion execution.",
              "file": "packages/motion-dsl/src/motions/smoking-cigarette.ts"
            },
            {
              "type": "error",
              "code": "DOMAIN_SEMANTIC_ISSUE",
              "message": "No explicit handling is provided for missing optional bones, which can lead to animation failure when specific bones are absent in the rig.",
              "file": "packages/motion-dsl/src/motions/smoking-cigarette.ts"
            }
          ],
          "context": {
            "filesAnalyzed": [
              "smoking-cigarette.ts"
            ],
            "rulesApplied": [],
            "philosophy": [
              "Motions must be anatomically accurate and biomechanically sound",
              "Every motion should utilize maximum bone engagement for realism",
              "Transitions between motions must be fluid and seamless",
              "Code must be deterministic - same seed produces same animation",
              "Movements should feel organic through layered animation and secondary motion",
              "All motions must gracefully handle missing optional bones",
              "Performance is critical - updates must complete in under 2ms",
              "Physics-based spring dynamics create natural acceleration curves",
              "Micro-movements and noise add life to static poses"
            ],
            "summary": "The block exposes a well-structured state machine and parametric variations, adhering largely to domain rules. However, it failed validation due to ambiguities in the state transitions, missing handling for optional bones, and insufficient clarity in parameter influences on the animations."
          },
          "ai": {
            "provider": "openai",
            "model": "gpt-4o-mini",
            "prompt": "Block Name: smoking_cigarette\n\n\nBLOCKS PHILOSOPHY:\n- Motions must be anatomically accurate and biomechanically sound\n- Every motion should utilize maximum bone engagement for realism\n- Transitions between motions must be fluid and seamless\n- Code must be deterministic - same seed produces same animation\n- Movements should feel organic through layered animation and secondary motion\n- All motions must gracefully handle missing optional bones\n- Performance is critical - updates must complete in under 2ms\n- Physics-based spring dynamics create natural acceleration curves\n- Micro-movements and noise add life to static poses\n\nBlock Definition:\n{\n  \"description\": \"Complete smoking animation with hand-to-mouth, inhale, exhale phases\",\n  \"path\": \"packages/motion-dsl/src/motions/smoking-cigarette.ts\",\n  \"inputs\": [\n    {\n      \"name\": \"rig\",\n      \"type\": \"entity.rig\"\n    },\n    {\n      \"name\": \"ctx\",\n      \"type\": \"entity.motion_context\"\n    }\n  ],\n  \"outputs\": [\n    {\n      \"name\": \"pose\",\n      \"type\": \"entity.motion_program\",\n      \"constraints\": [\n        \"Must implement state machine: idle, bring_to_mouth, inhale, hold, exhale, lower, ash_tap\",\n        \"Must use precise finger positioning for cigarette grip\",\n        \"Must coordinate breathing with inhale/exhale phases\",\n        \"Must use spring physics for arm movement\",\n        \"Must include secondary motion on fingers\",\n        \"Should squint eyes during inhale if available\",\n        \"Should animate jaw during exhale if available\"\n      ]\n    }\n  ]\n}\n\n\nBLOCK FILES:\n\n--- smoking-cigarette.ts ---\n```\n/**\n * Smoking Cigarette Motion\n *\n * Complete smoking animation with state machine for different phases:\n * idle holding, bring to mouth, inhale, hold, exhale, lower, ash tap.\n *\n * Research basis:\n * - Smoking biomechanics studies\n * - Hand-to-mouth coordination patterns\n * - Respiratory mechanics during smoking\n * - Habitual gesture timing\n */\n\nimport { z } from 'zod'\nimport type { MotionProgram, MotionMeta, HumanoidRig, MotionContext, VRMHumanBoneName } from '@posers/core'\nimport {\n  osc,\n  oscBreathing,\n  quatFromAxisAngle,\n  createNoiseGenerator,\n  createSpring,\n  Easing,\n  SpringPresets,\n  type NoiseGenerator,\n  type Spring,\n} from '@posers/core'\nimport {\n  BoneChains,\n  applyCigaretteGrip,\n  applyFingerCurl,\n} from '../blend'\n\n// ============================================================================\n// SCHEMA & TYPES\n// ============================================================================\n\nexport const smokingCigaretteParamsSchema = z.object({\n  /** Smoking style: casual, stressed, or seductive. Default: casual */\n  smokingStyle: z.enum(['casual', 'stressed', 'seductive']).default('casual'),\n  /** Which hand holds the cigarette. Default: right */\n  handedness: z.enum(['left', 'right']).default('right'),\n  /** Depth of inhale (0-1). Default: 0.7 */\n  inhaleDepth: z.number().min(0).max(1).default(0.7),\n  /** Variation in pacing (0-1). Default: 0.3 */\n  paceVariation: z.number().min(0).max(1).default(0.3),\n  /** Overall animation intensity (0-1). Default: 0.8 */\n  intensity: z.number().min(0).max(1).default(0.8),\n  /** Enable eye squint during inhale. Default: true */\n  eyeSquint: z.boolean().default(true),\n  /** Enable jaw animation during exhale. Default: true */\n  jawAnimation: z.boolean().default(true),\n  /** Time between puffs in seconds. Default: 8 */\n  puffInterval: z.number().min(3).max(20).default(8),\n})\n\nexport type SmokingCigaretteParams = z.infer<typeof smokingCigaretteParamsSchema>\nexport type SmokingCigaretteInput = z.input<typeof smokingCigaretteParamsSchema>\n\nexport const smokingCigaretteMeta: MotionMeta = {\n  id: 'smoking-cigarette',\n  name: 'Smoking Cigarette',\n  description: 'Complete smoking animation with hand-to-mouth, inhale, exhale phases',\n  tags: ['smoking', 'gesture', 'complex', 'state-machine'],\n  author: 'posers',\n}\n\n// ============================================================================\n// STATE MACHINE\n// ============================================================================\n\ntype SmokingPhase =\n  | 'idle'           // Holding cigarette at side\n  | 'bring_to_mouth' // Raising arm to mouth\n  | 'inhale'         // Taking a drag\n  | 'hold'           // Holding smoke\n  | 'exhale'         // Breathing out\n  | 'lower'          // Lowering arm\n  | 'ash_tap'        // Tapping ash off\n\ninterface SmokingState {\n  noise: NoiseGenerator\n  phase: SmokingPhase\n  phaseTime: number\n  phaseDuration: number\n  armSpringX: Spring\n  armSpringY: Spring\n  armSpringZ: Spring\n  wristSpring: Spring\n  chestSpring: Spring\n  lastPuffTime: number\n  ashTapPending: boolean\n  blinkTimer: number\n  isBlinking: boolean\n}\n\nconst PHASE_DURATIONS = {\n  idle: { base: 6, variance: 2 },\n  bring_to_mouth: { base: 0.8, variance: 0.2 },\n  inhale: { base: 1.5, variance: 0.3 },\n  hold: { base: 0.8, variance: 0.3 },\n  exhale: { base: 2.0, variance: 0.4 },\n  lower: { base: 0.6, variance: 0.15 },\n  ash_tap: { base: 0.4, variance: 0.1 },\n}\n\nfunction initState(seed: number): SmokingState {\n  return {\n    noise: createNoiseGenerator(seed),\n    phase: 'idle',\n    phaseTime: 0,\n    phaseDuration: PHASE_DURATIONS.idle.base,\n    armSpringX: createSpring(SpringPresets.smooth),\n    armSpringY: createSpring(SpringPresets.smooth),\n    armSpringZ: createSpring(SpringPresets.smooth),\n    wristSpring: createSpring({ stiffness: 250, damping: 22 }),\n    chestSpring: createSpring({ stiffness: 100, damping: 18 }),\n    lastPuffTime: -10,\n    ashTapPending: false,\n    blinkTimer: 0,\n    isBlinking: false,\n  }\n}\n\nfunction getNextPhase(current: SmokingPhase, ashTapPending: boolean): SmokingPhase {\n  switch (current) {\n    case 'idle': return 'bring_to_mouth'\n    case 'bring_to_mouth': return 'inhale'\n    case 'inhale': return 'hold'\n    case 'hold': return 'exhale'\n    case 'exhale': return ashTapPending ? 'ash_tap' : 'lower'\n    case 'lower': return 'idle'\n    case 'ash_tap': return 'lower'\n  }\n}\n\nfunction getPhaseDuration(phase: SmokingPhase, variation: number, noise: NoiseGenerator, t: number): number {\n  const { base, variance } = PHASE_DURATIONS[phase]\n  return base + noise.noise2D(t, phase.length * 100) * variance * variation\n}\n\n// ============================================================================\n// MOTION IMPLEMENTATION\n// ============================================================================\n\nexport function createSmokingCigarette(params: SmokingCigaretteInput = {}): MotionProgram<SmokingCigaretteParams> {\n  const validatedParams = smokingCigaretteParamsSchema.parse(params)\n  let state: SmokingState | null = null\n\n  return {\n    meta: smokingCigaretteMeta,\n    paramsSchema: smokingCigaretteParamsSchema,\n\n    init(_rig: HumanoidRig, ctx: MotionContext): void {\n      state = initState(ctx.seed)\n    },\n\n    update(rig: HumanoidRig, ctx: MotionContext, t: number, dt: number): void {\n      if (!state) {\n        state = initState(ctx.seed)\n      }\n\n      const {\n        smokingStyle,\n        handedness,\n        inhaleDepth,\n        paceVariation,\n        intensity,\n        eyeSquint,\n        jawAnimation,\n        puffInterval,\n      } = validatedParams\n\n      const noise = state.noise\n      const isRightHanded = handedness === 'right'\n      const handSide = isRightHanded ? 1 : -1\n\n      // Style modifiers\n      const styleModifiers = {\n        casual: { speed: 1, tension: 0.3, lean: 0 },\n        stressed: { speed: 1.3, tension: 0.7, lean: 0.05 },\n        seductive: { speed: 0.7, tension: 0.2, lean: -0.03 },\n      }[smokingStyle]\n\n      // ========================================\n      // STATE MACHINE UPDATE\n      // ========================================\n\n      state.phaseTime += dt\n\n      // Check for phase transition\n      if (state.phaseTime >= state.phaseDuration) {\n        const nextPhase = getNextPhase(state.phase, state.ashTapPending)\n        state.phase = nextPhase\n        state.phaseTime = 0\n        state.phaseDuration = getPhaseDuration(nextPhase, paceVariation, noise, t) / styleModifiers.speed\n\n        if (nextPhase === 'idle') {\n          state.lastPuffTime = t\n          // Randomly decide if next cycle should include ash tap\n          state.ashTapPending = noise.noise2D(t, 500) > 0.7\n        }\n      }\n\n      // Force transition if puff interval exceeded during idle\n      if (state.phase === 'idle' && (t - state.lastPuffTime) > puffInterval) {\n        state.phase = 'bring_to_mouth'\n        state.phaseTime = 0\n        state.phaseDuration = getPhaseDuration('bring_to_mouth', paceVariation, noise, t) / styleModifiers.speed\n      }\n\n      const phaseProgress = Math.min(1, state.phaseTime / state.phaseDuration)\n\n      // ========================================\n      // LAYER 1: BASE POSTURE\n      // ========================================\n\n      // Style-based lean\n      if (rig.hasBone('hips')) {\n        const leanAmount = styleModifiers.lean * intensity\n        rig.setRotation('hips', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, leanAmount))\n      }\n\n      // Relaxed spine\n      if (rig.hasBone('spine')) {\n        rig.setRotation('spine', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, 0.02 * intensity))\n      }\n\n      // ========================================\n      // LAYER 2: ARM MOVEMENT (SPRING-BASED)\n      // ========================================\n\n      // Define arm targets for each phase\n      let armTargetX = 0 // Forward/back rotation\n      let armTargetY = 0 // Abduction\n      let armTargetZ = 0 // Twist\n      let elbowBend = 0.2 * intensity\n      let wristRotation = 0\n\n      const smokingArm = isRightHanded ? 'right' : 'left'\n      const supportArm = isRightHanded ? 'left' : 'right'\n\n      switch (state.phase) {\n        case 'idle':\n          armTargetX = 0.1 * intensity\n          armTargetY = 0.15 * intensity\n          armTargetZ = 0\n          elbowBend = 0.3 * intensity\n          wristRotation = 0.1 * handSide\n          break\n\n        case 'bring_to_mouth':\n          const raiseEase = Easing.armRaise(phaseProgress)\n          armTargetX = -0.5 * intensity * raiseEase\n          armTargetY = 0.4 * intensity * raiseEase\n          armTargetZ = handSide * 0.2 * intensity * raiseEase\n          elbowBend = 1.4 * intensity * raiseEase\n          wristRotation = handSide * 0.3 * raiseEase\n          break\n\n        case 'inhale':\n          armTargetX = -0.5 * intensity\n          armTargetY = 0.4 * intensity\n          armTargetZ = handSide * 0.2 * intensity\n          elbowBend = 1.4 * intensity\n          wristRotation = handSide * 0.3\n          break\n\n        case 'hold':\n          // Slight arm lower while holding\n          const holdProgress = Easing.easeInOutCubic(phaseProgress)\n          armTargetX = -0.4 * intensity\n          armTargetY = 0.35 * intensity\n          armTargetZ = handSide * 0.18 * intensity\n          elbowBend = 1.3 * intensity\n          wristRotation = handSide * 0.25\n          break\n\n        case 'exhale':\n          // Arm stays relatively high during exhale\n          const exhaleProgress = Easing.easeInOutCubic(phaseProgress)\n          armTargetX = -0.35 * intensity * (1 - exhaleProgress * 0.5)\n          armTargetY = 0.3 * intensity * (1 - exhaleProgress * 0.3)\n          armTargetZ = handSide * 0.15 * intensity\n          elbowBend = 1.1 * intensity * (1 - exhaleProgress * 0.3)\n          wristRotation = handSide * 0.2\n          break\n\n        case 'lower':\n          const lowerEase = Easing.easeInCubic(phaseProgress)\n          armTargetX = 0.1 * intensity * lowerEase\n          armTargetY = 0.15 * intensity * lowerEase\n          armTargetZ = 0\n          elbowBend = 0.3 * intensity * lowerEase + 1.1 * intensity * (1 - lowerEase)\n          wristRotation = handSide * 0.1 * lowerEase\n          break\n\n        case 'ash_tap':\n          // Quick wrist flick\n          const tapEase = Math.sin(phaseProgress * Math.PI * 2)\n          armTargetX = 0.1 * intensity\n          armTargetY = 0.15 * intensity\n          armTargetZ = 0\n          elbowBend = 0.4 * intensity\n          wristRotation = handSide * 0.1 + tapEase * 0.3 * handSide\n          break\n      }\n\n      // Apply spring smoothing to arm movements\n      state.armSpringX.setTarget(armTargetX)\n      state.armSpringY.setTarget(armTargetY)\n      state.armSpringZ.setTarget(armTargetZ)\n      state.wristSpring.setTarget(wristRotation)\n\n      state.armSpringX.update(dt)\n      state.armSpringY.update(dt)\n      state.armSpringZ.update(dt)\n      state.wristSpring.update(dt)\n\n      const smoothArmX = state.armSpringX.value\n      const smoothArmY = state.armSpringY.value\n      const smoothArmZ = state.armSpringZ.value\n      const smoothWrist = state.wristSpring.value\n\n      // Apply smoking arm\n      const upperArmBone = `${smokingArm}UpperArm` as VRMHumanBoneName\n      const lowerArmBone = `${smokingArm}LowerArm` as VRMHumanBoneName\n      const handBone = `${smokingArm}Hand` as VRMHumanBoneName\n      const shoulderBone = `${smokingArm}Shoulder` as VRMHumanBoneName\n\n      if (rig.hasBone(shoulderBone)) {\n        rig.setRotation(shoulderBone, quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -handSide * smoothArmY * 0.15))\n      }\n\n      if (rig.hasBone(upperArmBone)) {\n        const upperArmRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, smoothArmX)\n        upperArmRot.multiply(quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -handSide * smoothArmY))\n        upperArmRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, smoothArmZ))\n        rig.setRotation(upperArmBone, upperArmRot)\n      }\n\n      if (rig.hasBone(lowerArmBone)) {\n        rig.setRotation(lowerArmBone, quatFromAxisAngle({ x: 0, y: 1, z: 0 }, handSide * elbowBend))\n      }\n\n      if (rig.hasBone(handBone)) {\n        const handRot = quatFromAxisAngle({ x: 0, y: 0, z: 1 }, smoothWrist)\n        // Slight wrist extension when holding cigarette up\n        const wristExtension = (state.phase === 'inhale' || state.phase === 'hold') ? 0.15 : 0\n        handRot.multiply(quatFromAxisAngle({ x: 1, y: 0, z: 0 }, wristExtension))\n        rig.setRotation(handBone, handRot)\n      }\n\n      // Apply cigarette grip to smoking hand\n      applyCigaretteGrip(rig, smokingArm as 'left' | 'right', 'between')\n\n      // Support arm - relaxed or crossed\n      const supportUpperArm = `${supportArm}UpperArm` as VRMHumanBoneName\n      const supportLowerArm = `${supportArm}LowerArm` as VRMHumanBoneName\n\n      if (smokingStyle === 'seductive') {\n        // Arm crossed under\n        if (rig.hasBone(supportUpperArm)) {\n          const supportRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, 0.4 * intensity)\n          supportRot.multiply(quatFromAxisAngle({ x: 0, y: 0, z: 1 }, handSide * 0.3 * intensity))\n          rig.setRotation(supportUpperArm, supportRot)\n        }\n        if (rig.hasBone(supportLowerArm)) {\n          rig.setRotation(supportLowerArm, quatFromAxisAngle({ x: 0, y: 1, z: 0 }, -handSide * 1.2 * intensity))\n        }\n      } else {\n        // Relaxed at side\n        if (rig.hasBone(supportUpperArm)) {\n          rig.setRotation(supportUpperArm, quatFromAxisAngle({ x: 0, y: 0, z: 1 }, handSide * 0.08))\n        }\n        if (rig.hasBone(supportLowerArm)) {\n          rig.setRotation(supportLowerArm, quatFromAxisAngle({ x: 0, y: 1, z: 0 }, -handSide * 0.15))\n        }\n        // Relaxed fingers on support hand\n        applyFingerCurl(rig, supportArm as 'left' | 'right', {\n          thumb: 0.3,\n          index: 0.35,\n          middle: 0.4,\n          ring: 0.45,\n          little: 0.5,\n        })\n      }\n\n      // ========================================\n      // LAYER 3: BREATHING & CHEST\n      // ========================================\n\n      let chestExpansion = 0\n      const baseBreath = oscBreathing(t, 0.2, 0.3) * intensity\n\n      switch (state.phase) {\n        case 'inhale':\n          // Deep inhale - chest expands\n          chestExpansion = Easing.easeInCubic(phaseProgress) * inhaleDepth * 0.06\n          break\n        case 'hold':\n          // Held breath\n          chestExpansion = inhaleDepth * 0.06\n          break\n        case 'exhale':\n          // Slow exhale\n          chestExpansion = inhaleDepth * 0.06 * (1 - Easing.easeOutCubic(phaseProgress))\n          break\n        default:\n          chestExpansion = baseBreath * 0.02\n      }\n\n      state.chestSpring.setTarget(chestExpansion)\n      state.chestSpring.update(dt)\n      const smoothChest = state.chestSpring.value\n\n      if (rig.hasBone('chest')) {\n        rig.setRotation('chest', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -smoothChest))\n      }\n      if (rig.hasBone('upperChest')) {\n        rig.setRotation('upperChest', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -smoothChest * 1.5))\n      }\n\n      // Shoulders rise with inhale\n      const shoulderRise = state.phase === 'inhale' ? phaseProgress * 0.02 * inhaleDepth : 0\n      if (rig.hasBone('leftShoulder')) {\n        rig.addRotation('leftShoulder', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -shoulderRise))\n      }\n      if (rig.hasBone('rightShoulder')) {\n        rig.addRotation('rightShoulder', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, shoulderRise))\n      }\n\n      // ========================================\n      // LAYER 4: HEAD MOVEMENT\n      // ========================================\n\n      let headTiltX = 0\n      let headTiltY = 0\n\n      switch (state.phase) {\n        case 'inhale':\n          // Slight head tilt back during inhale\n          headTiltX = -0.05 * phaseProgress * intensity\n          break\n        case 'exhale':\n          // Head forward/up for exhale\n          headTiltX = 0.03 * (1 - phaseProgress) * intensity\n          headTiltY = handSide * 0.02 * phaseProgress * intensity\n          break\n        default:\n          // Subtle idle movement\n          headTiltX = noise.noise2D(t * 0.2, 600) * 0.02 * intensity\n          headTiltY = noise.noise2D(t * 0.15, 700) * 0.025 * intensity\n      }\n\n      if (rig.hasBone('head')) {\n        const headRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, headTiltX)\n        headRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, headTiltY))\n        rig.setRotation('head', headRot)\n      }\n      if (rig.hasBone('neck')) {\n        rig.setRotation('neck', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, headTiltX * 0.4))\n      }\n\n      // ========================================\n      // LAYER 5: EYES\n      // ========================================\n\n      if (eyeSquint) {\n        let eyeSquintAmount = 0\n\n        if (state.phase === 'inhale') {\n          eyeSquintAmount = phaseProgress * 0.15 * intensity\n        } else if (state.phase === 'hold') {\n          eyeSquintAmount = 0.15 * intensity\n        } else if (state.phase === 'exhale') {\n          eyeSquintAmount = 0.15 * intensity * (1 - phaseProgress)\n        }\n\n        // Eye rotation for squint effect\n        if (rig.hasBone('leftEye')) {\n          rig.setRotation('leftEye', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, eyeSquintAmount))\n        }\n        if (rig.hasBone('rightEye')) {\n          rig.setRotation('rightEye', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, eyeSquintAmount))\n        }\n      }\n\n      // Blinking\n      const blinkChance = noise.noise2D(t * 0.3, 800)\n      if (!state.isBlinking && blinkChance > 0.95) {\n        state.isBlinking = true\n        state.blinkTimer = 0\n      }\n\n      if (state.isBlinking) {\n        state.blinkTimer += dt\n        if (state.blinkTimer > 0.15) {\n          state.isBlinking = false\n        } else {\n          const blinkProgress = Math.sin(state.blinkTimer / 0.15 * Math.PI)\n          if (rig.hasBone('leftEye')) {\n            rig.addRotation('leftEye', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -blinkProgress * 0.25))\n          }\n          if (rig.hasBone('rightEye')) {\n            rig.addRotation('rightEye', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -blinkProgress * 0.25))\n          }\n        }\n      }\n\n      // ========================================\n      // LAYER 6: JAW (EXHALE)\n      // ========================================\n\n      if (jawAnimation && rig.hasBone('jaw')) {\n        let jawOpen = 0\n\n        if (state.phase === 'exhale') {\n          // Open slightly for exhale\n          const exhaleJaw = Math.sin(phaseProgress * Math.PI) * 0.08 * intensity\n          jawOpen = exhaleJaw\n        }\n\n        rig.setRotation('jaw', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, jawOpen))\n      }\n\n      // ========================================\n      // LAYER 7: LEGS & WEIGHT\n      // ========================================\n\n      // Relaxed stance with slight weight shift\n      const weightShift = noise.noise2D(t * 0.1, 900) * 0.03 * intensity\n\n      if (rig.hasBone('leftUpperLeg')) {\n        rig.setRotation('leftUpperLeg', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, 0.02 + weightShift))\n      }\n      if (rig.hasBone('rightUpperLeg')) {\n        rig.setRotation('rightUpperLeg', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, 0.03 - weightShift))\n      }\n      if (rig.hasBone('leftLowerLeg')) {\n        rig.setRotation('leftLowerLeg', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -0.05))\n      }\n      if (rig.hasBone('rightLowerLeg')) {\n        rig.setRotation('rightLowerLeg', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -0.08))\n      }\n\n      // Feet slightly turned out\n      if (rig.hasBone('leftFoot')) {\n        rig.setRotation('leftFoot', quatFromAxisAngle({ x: 0, y: 1, z: 0 }, -0.1))\n      }\n      if (rig.hasBone('rightFoot')) {\n        rig.setRotation('rightFoot', quatFromAxisAngle({ x: 0, y: 1, z: 0 }, 0.15))\n      }\n    },\n  }\n}\n\nexport const smokingCigarette: MotionProgram<SmokingCigaretteParams> = createSmokingCigarette({})\n\n```\n\n\nVALIDATION TASK:\nAnalyze ALL files together to determine if this block:\n1. Expresses domain intent clearly in source code\n2. Uses specified inputs/outputs correctly\n3. Adheres to all domain rules\n4. For templates: Check if template SOURCE contains semantic HTML, ARIA labels, media queries, heading hierarchy\n5. Does NOT introduce undocumented concepts\n\nReturn validation issues with specific file references where possible.\nAlso provide a brief summary explaining why the block passed or failed validation.",
            "response": "{\n  \"isValid\": false,\n  \"issues\": [\n    {\n      \"message\": \"The state machine lacks clear implementation of the 'ash_tap' state in terms of animation transitions, which may lead to non-deterministic behavior during the animation sequence.\",\n      \"severity\": \"warning\",\n      \"file\": \"packages/motion-dsl/src/motions/smoking-cigarette.ts\"\n    },\n    {\n      \"message\": \"The use of `handedness` and its effect on the animation is not fully accounted for in transition logic (e.g., different animations for left vs right hand) which can cause ambiguity in animations for left-handed users.\",\n      \"severity\": \"warning\",\n      \"file\": \"packages/motion-dsl/src/motions/smoking-cigarette.ts\"\n    },\n    {\n      \"message\": \"Certain parameters like `intensity` do not clearly quantify their influence on the animation, leading to potential inconsistencies in motion execution.\",\n      \"severity\": \"warning\",\n      \"file\": \"packages/motion-dsl/src/motions/smoking-cigarette.ts\"\n    },\n    {\n      \"message\": \"No explicit handling is provided for missing optional bones, which can lead to animation failure when specific bones are absent in the rig.\",\n      \"severity\": \"error\",\n      \"file\": \"packages/motion-dsl/src/motions/smoking-cigarette.ts\"\n    }\n  ],\n  \"summary\": \"The block exposes a well-structured state machine and parametric variations, adhering largely to domain rules. However, it failed validation due to ambiguities in the state transitions, missing handling for optional bones, and insufficient clarity in parameter influences on the animations.\"\n}",
            "tokensUsed": {
              "input": 6233,
              "output": 286
            }
          }
        }
      ],
      "cache": {
        "decision": "Force mode: running all validators",
        "skippedValidators": 0,
        "revalidationReason": "force_flag"
      }
    },
    {
      "blockName": "seductive_walk",
      "blockPath": "/Users/ajaxdavis/repos/lisa/posers/packages/motion-dsl/src/motions/seductive-walk.ts",
      "hasErrors": false,
      "hasWarnings": false,
      "validators": [
        {
          "id": "schema.io",
          "label": "schema",
          "passed": true,
          "duration": 0,
          "issues": [],
          "context": {
            "filesAnalyzed": [
              "blocks.yml"
            ],
            "rulesApplied": [
              "input_schema_complete",
              "output_schema_complete",
              "block_has_description"
            ],
            "summary": "Schema validation passed. Validated 2 input(s) and 1 output(s). All schemas are complete with name and type fields.",
            "input": {
              "blockName": "seductive_walk",
              "inputs": [
                {
                  "name": "rig",
                  "type": "entity.rig"
                },
                {
                  "name": "ctx",
                  "type": "entity.motion_context"
                }
              ],
              "outputs": [
                {
                  "name": "pose",
                  "type": "entity.motion_program",
                  "constraints": [
                    "Must implement full gait cycle with proper phase timing",
                    "Must include hip sway with spine counter-rotation",
                    "Must animate all leg bones including toes if available",
                    "Must include fluid arm swing with wrist rotation",
                    "Must keep head stable with slight tilt",
                    "Should use crossover step pattern",
                    "Should include secondary motion for follow-through"
                  ]
                }
              ],
              "description": "Runway-style walk with exaggerated hip sway and fluid arm movement",
              "path": "packages/motion-dsl/src/motions/seductive-walk.ts"
            },
            "output": {
              "checksPerformed": [
                "Validating 2 input definition(s)",
                "  ✓ Input \"rig\" has valid schema (type: entity.rig)",
                "  ✓ Input \"ctx\" has valid schema (type: entity.motion_context)",
                "Validating 1 output definition(s)",
                "  ✓ Output \"pose\" has valid schema (type: entity.motion_program)",
                "✓ Block has description: \"Runway-style walk with exaggerated hip sway and fl...\""
              ],
              "inputCount": 2,
              "outputCount": 1,
              "hasDescription": true
            }
          }
        },
        {
          "id": "domain.validation",
          "label": "domain",
          "passed": true,
          "duration": 2520,
          "issues": [],
          "context": {
            "filesAnalyzed": [
              "seductive-walk.ts"
            ],
            "rulesApplied": [],
            "philosophy": [
              "Motions must be anatomically accurate and biomechanically sound",
              "Every motion should utilize maximum bone engagement for realism",
              "Transitions between motions must be fluid and seamless",
              "Code must be deterministic - same seed produces same animation",
              "Movements should feel organic through layered animation and secondary motion",
              "All motions must gracefully handle missing optional bones",
              "Performance is critical - updates must complete in under 2ms",
              "Physics-based spring dynamics create natural acceleration curves",
              "Micro-movements and noise add life to static poses"
            ],
            "summary": "The block 'seductive_walk' adheres to domain semantics effectively by implementing detailed biomechanical principles, demonstrating accurate domain intent through robust state management, fluid movements, and proper handling of optional bones. All specified inputs and outputs are utilized as intended, fulfilling the constraints outlined in the block definition."
          },
          "ai": {
            "provider": "openai",
            "model": "gpt-4o-mini",
            "prompt": "Block Name: seductive_walk\n\n\nBLOCKS PHILOSOPHY:\n- Motions must be anatomically accurate and biomechanically sound\n- Every motion should utilize maximum bone engagement for realism\n- Transitions between motions must be fluid and seamless\n- Code must be deterministic - same seed produces same animation\n- Movements should feel organic through layered animation and secondary motion\n- All motions must gracefully handle missing optional bones\n- Performance is critical - updates must complete in under 2ms\n- Physics-based spring dynamics create natural acceleration curves\n- Micro-movements and noise add life to static poses\n\nBlock Definition:\n{\n  \"description\": \"Runway-style walk with exaggerated hip sway and fluid arm movement\",\n  \"path\": \"packages/motion-dsl/src/motions/seductive-walk.ts\",\n  \"inputs\": [\n    {\n      \"name\": \"rig\",\n      \"type\": \"entity.rig\"\n    },\n    {\n      \"name\": \"ctx\",\n      \"type\": \"entity.motion_context\"\n    }\n  ],\n  \"outputs\": [\n    {\n      \"name\": \"pose\",\n      \"type\": \"entity.motion_program\",\n      \"constraints\": [\n        \"Must implement full gait cycle with proper phase timing\",\n        \"Must include hip sway with spine counter-rotation\",\n        \"Must animate all leg bones including toes if available\",\n        \"Must include fluid arm swing with wrist rotation\",\n        \"Must keep head stable with slight tilt\",\n        \"Should use crossover step pattern\",\n        \"Should include secondary motion for follow-through\"\n      ]\n    }\n  ]\n}\n\n\nBLOCK FILES:\n\n--- seductive-walk.ts ---\n```\n/**\n * Seductive Walk Motion\n *\n * Runway-style walking with exaggerated hip sway, fluid arm movement,\n * and confident head carriage. Full gait cycle implementation with\n * crossover step pattern.\n *\n * Research basis:\n * - Runway/catwalk biomechanics\n * - Hip kinematics during walking\n * - Arm swing dynamics and coordination\n * - Weight transfer patterns\n * - Secondary motion physics\n */\n\nimport { z } from 'zod'\nimport { Vector3 } from 'three'\nimport type { MotionProgram, MotionMeta, HumanoidRig, MotionContext, VRMHumanBoneName } from '@posers/core'\nimport {\n  osc,\n  quatFromAxisAngle,\n  createNoiseGenerator,\n  createSpring,\n  Easing,\n  walkPhase,\n  type NoiseGenerator,\n  type Spring,\n} from '@posers/core'\nimport {\n  BoneChains,\n  getAvailableBones,\n  applyFingerCurl,\n  applyFingerSpread,\n} from '../blend'\n\n// ============================================================================\n// SCHEMA & TYPES\n// ============================================================================\n\nexport const seductiveWalkParamsSchema = z.object({\n  /** Overall intensity of exaggeration (0-1). Default: 0.7 */\n  intensity: z.number().min(0).max(1).default(0.7),\n  /** Walking speed (steps per second). Default: 0.8 */\n  speed: z.number().min(0.3).max(2).default(0.8),\n  /** Amount of hip sway (0-1). Default: 0.8 */\n  hipSwayAmount: z.number().min(0).max(1).default(0.8),\n  /** Fluidity of arm movement (0-1). Default: 0.7 */\n  armFlowiness: z.number().min(0).max(1).default(0.7),\n  /** Head tilt angle (0-1). Default: 0.3 */\n  headTilt: z.number().min(0).max(1).default(0.3),\n  /** Enable crossover step pattern. Default: true */\n  crossoverStep: z.boolean().default(true),\n  /** Enable toe point during swing. Default: true */\n  toePoint: z.boolean().default(true),\n  /** Enable secondary motion (follow-through). Default: true */\n  secondaryMotion: z.boolean().default(true),\n  /** Enable finger movement. Default: true */\n  fingerAnimation: z.boolean().default(true),\n})\n\nexport type SeductiveWalkParams = z.infer<typeof seductiveWalkParamsSchema>\nexport type SeductiveWalkInput = z.input<typeof seductiveWalkParamsSchema>\n\nexport const seductiveWalkMeta: MotionMeta = {\n  id: 'seductive-walk',\n  name: 'Seductive Walk',\n  description: 'Runway-style walk with exaggerated hip sway and fluid arm movement',\n  tags: ['walk', 'locomotion', 'seductive', 'runway'],\n  author: 'posers',\n}\n\n// ============================================================================\n// GAIT CYCLE HELPERS\n// ============================================================================\n\n/**\n * Gait cycle phases (0-1):\n * 0.0 - 0.1: Right heel strike / Left toe off\n * 0.1 - 0.3: Right loading response\n * 0.3 - 0.5: Right midstance / Left swing\n * 0.5 - 0.6: Left heel strike / Right toe off\n * 0.6 - 0.8: Left loading response\n * 0.8 - 1.0: Left midstance / Right swing\n */\n\nfunction getGaitPhase(t: number, speed: number): number {\n  const cycleTime = 1 / speed\n  return (t / cycleTime) % 1\n}\n\nfunction legSwingCurve(phase: number): number {\n  // Smooth leg swing with acceleration\n  return Easing.easeInOutSine(phase)\n}\n\nfunction hipDropCurve(phase: number): number {\n  // Hip drops during swing phase, rises during stance\n  return Math.sin(phase * Math.PI * 2)\n}\n\nfunction armSwingCurve(phase: number, flowiness: number): number {\n  // Fluid arm swing with follow-through\n  const base = Math.sin(phase * Math.PI * 2)\n  const secondary = Math.sin((phase * Math.PI * 2) - 0.3) * 0.2 * flowiness\n  return base + secondary\n}\n\n// ============================================================================\n// STATE MANAGEMENT\n// ============================================================================\n\ninterface SeductiveWalkState {\n  noise: NoiseGenerator\n  hipSpring: Spring\n  shoulderSpring: Spring\n  headSpring: Spring\n  leftArmSpring: Spring\n  rightArmSpring: Spring\n  blinkTimer: number\n  isBlinking: boolean\n}\n\nfunction initState(seed: number): SeductiveWalkState {\n  return {\n    noise: createNoiseGenerator(seed),\n    hipSpring: createSpring({ stiffness: 150, damping: 15 }),\n    shoulderSpring: createSpring({ stiffness: 120, damping: 12 }),\n    headSpring: createSpring({ stiffness: 180, damping: 20 }),\n    leftArmSpring: createSpring({ stiffness: 80, damping: 10 }),\n    rightArmSpring: createSpring({ stiffness: 80, damping: 10 }),\n    blinkTimer: 0,\n    isBlinking: false,\n  }\n}\n\n// ============================================================================\n// MOTION IMPLEMENTATION\n// ============================================================================\n\nexport function createSeductiveWalk(params: SeductiveWalkInput = {}): MotionProgram<SeductiveWalkParams> {\n  const validatedParams = seductiveWalkParamsSchema.parse(params)\n  let state: SeductiveWalkState | null = null\n\n  return {\n    meta: seductiveWalkMeta,\n    paramsSchema: seductiveWalkParamsSchema,\n\n    init(_rig: HumanoidRig, ctx: MotionContext): void {\n      state = initState(ctx.seed)\n    },\n\n    update(rig: HumanoidRig, ctx: MotionContext, t: number, dt: number): void {\n      if (!state) {\n        state = initState(ctx.seed)\n      }\n\n      const {\n        intensity,\n        speed,\n        hipSwayAmount,\n        armFlowiness,\n        headTilt,\n        crossoverStep,\n        toePoint,\n        secondaryMotion,\n        fingerAnimation,\n      } = validatedParams\n\n      const noise = state.noise\n      const gaitPhase = getGaitPhase(t, speed)\n\n      // Which leg is in stance phase\n      const rightStance = gaitPhase < 0.5\n      const leftStance = !rightStance\n\n      // Swing phase for each leg (0-1 during their swing)\n      const rightSwingPhase = rightStance ? 0 : (gaitPhase - 0.5) * 2\n      const leftSwingPhase = leftStance ? 0 : gaitPhase * 2\n\n      // ========================================\n      // LAYER 1: HIP MOVEMENT (CORE OF THE WALK)\n      // ========================================\n\n      // Hip sway - lateral movement\n      const hipSwayTarget = Math.sin(gaitPhase * Math.PI * 2) * hipSwayAmount * 0.12 * intensity\n      state.hipSpring.setTarget(hipSwayTarget)\n      state.hipSpring.update(dt)\n      const hipSway = state.hipSpring.value\n\n      // Hip rotation (twist) - counter to shoulders\n      const hipTwist = Math.sin(gaitPhase * Math.PI * 2) * 0.08 * intensity\n\n      // Hip drop on swing side\n      const hipDrop = hipDropCurve(gaitPhase) * 0.05 * intensity\n\n      // Forward hip oscillation (pelvic tilt during gait)\n      const hipForward = Math.sin(gaitPhase * Math.PI * 4) * 0.02 * intensity\n\n      if (rig.hasBone('hips')) {\n        const hipsRot = quatFromAxisAngle({ x: 0, y: 0, z: 1 }, hipSway)\n        hipsRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, hipTwist))\n        hipsRot.multiply(quatFromAxisAngle({ x: 1, y: 0, z: 0 }, hipForward))\n        rig.setRotation('hips', hipsRot)\n\n        // Hip translation for bounce\n        const hipBounce = Math.abs(Math.sin(gaitPhase * Math.PI * 2)) * 0.01 * intensity\n        rig.setHipsPositionOffset(new Vector3(hipSway * 0.1, hipBounce, 0))\n      }\n\n      // ========================================\n      // LAYER 2: SPINE COUNTER-ROTATION\n      // ========================================\n\n      // Spine opposes hip movement for balance\n      const spineCounter = -hipTwist * 0.4\n      const spineSway = -hipSway * 0.3\n\n      if (rig.hasBone('spine')) {\n        const spineRot = quatFromAxisAngle({ x: 0, y: 1, z: 0 }, spineCounter * 0.5)\n        spineRot.multiply(quatFromAxisAngle({ x: 0, y: 0, z: 1 }, spineSway * 0.5))\n        rig.setRotation('spine', spineRot)\n      }\n\n      if (rig.hasBone('chest')) {\n        const chestRot = quatFromAxisAngle({ x: 0, y: 1, z: 0 }, spineCounter * 0.8)\n        chestRot.multiply(quatFromAxisAngle({ x: 0, y: 0, z: 1 }, spineSway * 0.3))\n        // Slight chest forward for confidence\n        chestRot.multiply(quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -0.03 * intensity))\n        rig.setRotation('chest', chestRot)\n      }\n\n      if (rig.hasBone('upperChest')) {\n        const upperChestRot = quatFromAxisAngle({ x: 0, y: 1, z: 0 }, spineCounter)\n        upperChestRot.multiply(quatFromAxisAngle({ x: 0, y: 0, z: 1 }, spineSway * 0.2))\n        upperChestRot.multiply(quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -0.04 * intensity))\n        rig.setRotation('upperChest', upperChestRot)\n      }\n\n      // ========================================\n      // LAYER 3: SHOULDER MOVEMENT\n      // ========================================\n\n      // Shoulders counter-rotate to hips\n      const shoulderTarget = -hipTwist * 0.6\n      state.shoulderSpring.setTarget(shoulderTarget)\n      state.shoulderSpring.update(dt)\n      const shoulderTwist = state.shoulderSpring.value\n\n      // Shoulder drop with arm swing\n      const leftShoulderDrop = armSwingCurve(gaitPhase, armFlowiness) * 0.02 * intensity\n      const rightShoulderDrop = armSwingCurve(gaitPhase + 0.5, armFlowiness) * 0.02 * intensity\n\n      if (rig.hasBone('leftShoulder')) {\n        const leftShoulderRot = quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -leftShoulderDrop)\n        rig.setRotation('leftShoulder', leftShoulderRot)\n      }\n\n      if (rig.hasBone('rightShoulder')) {\n        const rightShoulderRot = quatFromAxisAngle({ x: 0, y: 0, z: 1 }, rightShoulderDrop)\n        rig.setRotation('rightShoulder', rightShoulderRot)\n      }\n\n      // ========================================\n      // LAYER 4: ARM SWING\n      // ========================================\n\n      // Fluid arm swing with secondary motion\n      const leftArmSwingBase = armSwingCurve(gaitPhase, armFlowiness) * 0.35 * intensity * armFlowiness\n      const rightArmSwingBase = armSwingCurve(gaitPhase + 0.5, armFlowiness) * 0.35 * intensity * armFlowiness\n\n      // Apply spring for smoothness\n      state.leftArmSpring.setTarget(leftArmSwingBase)\n      state.rightArmSpring.setTarget(rightArmSwingBase)\n      state.leftArmSpring.update(dt)\n      state.rightArmSpring.update(dt)\n\n      const leftArmSwing = state.leftArmSpring.value\n      const rightArmSwing = state.rightArmSpring.value\n\n      // Secondary motion - wrist lag\n      const leftWristLag = secondaryMotion ? leftArmSwing * 0.3 : 0\n      const rightWristLag = secondaryMotion ? rightArmSwing * 0.3 : 0\n\n      if (rig.hasBone('leftUpperArm')) {\n        const leftUpperArmRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, leftArmSwing)\n        leftUpperArmRot.multiply(quatFromAxisAngle({ x: 0, y: 0, z: 1 }, 0.08 * intensity))\n        rig.setRotation('leftUpperArm', leftUpperArmRot)\n      }\n\n      if (rig.hasBone('rightUpperArm')) {\n        const rightUpperArmRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, rightArmSwing)\n        rightUpperArmRot.multiply(quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -0.08 * intensity))\n        rig.setRotation('rightUpperArm', rightUpperArmRot)\n      }\n\n      // Lower arms - slight bend with secondary motion\n      if (rig.hasBone('leftLowerArm')) {\n        const leftLowerRot = quatFromAxisAngle({ x: 0, y: 1, z: 0 }, -0.1 - leftWristLag * 0.2)\n        rig.setRotation('leftLowerArm', leftLowerRot)\n      }\n\n      if (rig.hasBone('rightLowerArm')) {\n        const rightLowerRot = quatFromAxisAngle({ x: 0, y: 1, z: 0 }, 0.1 + rightWristLag * 0.2)\n        rig.setRotation('rightLowerArm', rightLowerRot)\n      }\n\n      // Wrists - graceful rotation\n      if (rig.hasBone('leftHand')) {\n        const leftHandRot = quatFromAxisAngle({ x: 0, y: 0, z: 1 }, 0.1 + leftWristLag * 0.15)\n        leftHandRot.multiply(quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -leftWristLag * 0.1))\n        rig.setRotation('leftHand', leftHandRot)\n      }\n\n      if (rig.hasBone('rightHand')) {\n        const rightHandRot = quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -0.1 - rightWristLag * 0.15)\n        rightHandRot.multiply(quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -rightWristLag * 0.1))\n        rig.setRotation('rightHand', rightHandRot)\n      }\n\n      // ========================================\n      // LAYER 5: LEG MOVEMENT\n      // ========================================\n\n      // Right leg\n      const rightLegForward = rightStance\n        ? -0.1 * (gaitPhase * 2) * intensity // Pushing back during stance\n        : Math.sin(rightSwingPhase * Math.PI) * 0.4 * intensity // Swinging forward\n\n      const rightLegAbduction = crossoverStep\n        ? Math.sin(gaitPhase * Math.PI * 2 + Math.PI) * 0.05 * intensity // Crossover\n        : 0\n\n      if (rig.hasBone('rightUpperLeg')) {\n        const rightUpperLegRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, rightLegForward)\n        rightUpperLegRot.multiply(quatFromAxisAngle({ x: 0, y: 0, z: 1 }, rightLegAbduction))\n        rig.setRotation('rightUpperLeg', rightUpperLegRot)\n      }\n\n      // Right knee bend\n      const rightKneeBend = rightStance\n        ? 0.08 * intensity // Slight bend in stance\n        : Math.sin(rightSwingPhase * Math.PI) * 0.6 * intensity // Bend during swing\n\n      if (rig.hasBone('rightLowerLeg')) {\n        rig.setRotation('rightLowerLeg', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -rightKneeBend))\n      }\n\n      // Left leg\n      const leftLegForward = leftStance\n        ? -0.1 * ((gaitPhase - 0.5) * 2) * intensity\n        : Math.sin(leftSwingPhase * Math.PI) * 0.4 * intensity\n\n      const leftLegAbduction = crossoverStep\n        ? Math.sin(gaitPhase * Math.PI * 2) * 0.05 * intensity\n        : 0\n\n      if (rig.hasBone('leftUpperLeg')) {\n        const leftUpperLegRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, leftLegForward)\n        leftUpperLegRot.multiply(quatFromAxisAngle({ x: 0, y: 0, z: 1 }, leftLegAbduction))\n        rig.setRotation('leftUpperLeg', leftUpperLegRot)\n      }\n\n      const leftKneeBend = leftStance\n        ? 0.08 * intensity\n        : Math.sin(leftSwingPhase * Math.PI) * 0.6 * intensity\n\n      if (rig.hasBone('leftLowerLeg')) {\n        rig.setRotation('leftLowerLeg', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -leftKneeBend))\n      }\n\n      // ========================================\n      // LAYER 6: FEET & TOES\n      // ========================================\n\n      // Right foot\n      const rightFootAngle = rightStance\n        ? -0.1 * intensity // Flat/slight heel strike\n        : (toePoint ? -0.3 * Math.sin(rightSwingPhase * Math.PI) * intensity : 0) // Toe point during swing\n\n      if (rig.hasBone('rightFoot')) {\n        const rightFootRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, rightFootAngle)\n        rightFootRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, 0.05)) // Slight turn out\n        rig.setRotation('rightFoot', rightFootRot)\n      }\n\n      if (rig.hasBone('rightToes') && toePoint) {\n        const rightToePoint = rightStance ? 0 : Math.sin(rightSwingPhase * Math.PI) * 0.4 * intensity\n        rig.setRotation('rightToes', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -rightToePoint))\n      }\n\n      // Left foot\n      const leftFootAngle = leftStance\n        ? -0.1 * intensity\n        : (toePoint ? -0.3 * Math.sin(leftSwingPhase * Math.PI) * intensity : 0)\n\n      if (rig.hasBone('leftFoot')) {\n        const leftFootRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, leftFootAngle)\n        leftFootRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, -0.05))\n        rig.setRotation('leftFoot', leftFootRot)\n      }\n\n      if (rig.hasBone('leftToes') && toePoint) {\n        const leftToePoint = leftStance ? 0 : Math.sin(leftSwingPhase * Math.PI) * 0.4 * intensity\n        rig.setRotation('leftToes', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -leftToePoint))\n      }\n\n      // ========================================\n      // LAYER 7: HEAD (STABLE WITH TILT)\n      // ========================================\n\n      // Head stays relatively stable (vestibular reflex)\n      const headCompensation = -hipSway * 0.3\n      const headTiltAmount = headTilt * 0.08 * intensity\n\n      // Subtle look direction\n      const lookDirection = noise.noise2D(t * 0.1, 100) * 0.05 * intensity\n\n      state.headSpring.setTarget(headCompensation)\n      state.headSpring.update(dt)\n\n      if (rig.hasBone('head')) {\n        const headRot = quatFromAxisAngle({ x: 0, y: 0, z: 1 }, state.headSpring.value + headTiltAmount)\n        headRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, lookDirection))\n        // Slight chin up for confidence\n        headRot.multiply(quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -0.03 * intensity))\n        rig.setRotation('head', headRot)\n      }\n\n      if (rig.hasBone('neck')) {\n        const neckRot = quatFromAxisAngle({ x: 0, y: 0, z: 1 }, state.headSpring.value * 0.3)\n        neckRot.multiply(quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -0.02 * intensity))\n        rig.setRotation('neck', neckRot)\n      }\n\n      // ========================================\n      // LAYER 8: FINGERS\n      // ========================================\n\n      if (fingerAnimation) {\n        // Graceful, slightly spread fingers\n        const fingerCurl = 0.15 + noise.noise2D(t * 0.2, 200) * 0.05\n\n        applyFingerCurl(rig, 'left', {\n          thumb: fingerCurl * 0.4,\n          index: fingerCurl * 0.8,\n          middle: fingerCurl * 0.9,\n          ring: fingerCurl,\n          little: fingerCurl * 1.1,\n        })\n\n        applyFingerCurl(rig, 'right', {\n          thumb: fingerCurl * 0.4,\n          index: fingerCurl * 0.8,\n          middle: fingerCurl * 0.9,\n          ring: fingerCurl,\n          little: fingerCurl * 1.1,\n        })\n\n        // Elegant spread\n        applyFingerSpread(rig, 'left', 0.4 * intensity)\n        applyFingerSpread(rig, 'right', 0.4 * intensity)\n      }\n\n      // ========================================\n      // LAYER 9: EYES\n      // ========================================\n\n      // Confident forward gaze with subtle movement\n      const eyeX = noise.noise2D(t * 0.15, 300) * 0.03 * intensity\n      const eyeY = noise.noise2D(t * 0.12, 400) * 0.02 * intensity\n\n      // Blinking\n      const blinkChance = noise.noise2D(t * 0.25, 500)\n      if (!state.isBlinking && blinkChance > 0.95) {\n        state.isBlinking = true\n        state.blinkTimer = 0\n      }\n\n      let blinkAmount = 0\n      if (state.isBlinking) {\n        state.blinkTimer += dt\n        if (state.blinkTimer > 0.15) {\n          state.isBlinking = false\n        } else {\n          blinkAmount = Math.sin(state.blinkTimer / 0.15 * Math.PI) * 0.25\n        }\n      }\n\n      if (rig.hasBone('leftEye')) {\n        const leftEyeRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, eyeY - blinkAmount)\n        leftEyeRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, eyeX))\n        rig.setRotation('leftEye', leftEyeRot)\n      }\n\n      if (rig.hasBone('rightEye')) {\n        const rightEyeRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, eyeY - blinkAmount)\n        rightEyeRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, eyeX))\n        rig.setRotation('rightEye', rightEyeRot)\n      }\n    },\n  }\n}\n\nexport const seductiveWalk: MotionProgram<SeductiveWalkParams> = createSeductiveWalk({})\n\n```\n\n\nVALIDATION TASK:\nAnalyze ALL files together to determine if this block:\n1. Expresses domain intent clearly in source code\n2. Uses specified inputs/outputs correctly\n3. Adheres to all domain rules\n4. For templates: Check if template SOURCE contains semantic HTML, ARIA labels, media queries, heading hierarchy\n5. Does NOT introduce undocumented concepts\n\nReturn validation issues with specific file references where possible.\nAlso provide a brief summary explaining why the block passed or failed validation.",
            "response": "{\n  \"isValid\": true,\n  \"issues\": [],\n  \"summary\": \"The block 'seductive_walk' adheres to domain semantics effectively by implementing detailed biomechanical principles, demonstrating accurate domain intent through robust state management, fluid movements, and proper handling of optional bones. All specified inputs and outputs are utilized as intended, fulfilling the constraints outlined in the block definition.\"\n}",
            "tokensUsed": {
              "input": 6031,
              "output": 71
            }
          }
        }
      ],
      "cache": {
        "decision": "Force mode: running all validators",
        "skippedValidators": 0,
        "revalidationReason": "force_flag"
      }
    },
    {
      "blockName": "contemplative_lean",
      "blockPath": "/Users/ajaxdavis/repos/lisa/posers/packages/motion-dsl/src/motions/contemplative-lean.ts",
      "hasErrors": false,
      "hasWarnings": true,
      "validators": [
        {
          "id": "schema.io",
          "label": "schema",
          "passed": true,
          "duration": 0,
          "issues": [],
          "context": {
            "filesAnalyzed": [
              "blocks.yml"
            ],
            "rulesApplied": [
              "input_schema_complete",
              "output_schema_complete",
              "block_has_description"
            ],
            "summary": "Schema validation passed. Validated 2 input(s) and 1 output(s). All schemas are complete with name and type fields.",
            "input": {
              "blockName": "contemplative_lean",
              "inputs": [
                {
                  "name": "rig",
                  "type": "entity.rig"
                },
                {
                  "name": "ctx",
                  "type": "entity.motion_context"
                }
              ],
              "outputs": [
                {
                  "name": "pose",
                  "type": "entity.motion_program",
                  "constraints": [
                    "Must implement asymmetric weight distribution",
                    "Must include hand-to-chin or crossed arms pose",
                    "Must animate all finger bones for detailed hand pose",
                    "Must include slow contemplative breathing",
                    "Must add subtle weight shift micro-movements",
                    "Should include thinking gestures (head tilt, eye movement)",
                    "Should support multiple pose variants via parameters"
                  ]
                }
              ],
              "description": "Thoughtful asymmetric pose with weight on one leg and thinking gestures",
              "path": "packages/motion-dsl/src/motions/contemplative-lean.ts"
            },
            "output": {
              "checksPerformed": [
                "Validating 2 input definition(s)",
                "  ✓ Input \"rig\" has valid schema (type: entity.rig)",
                "  ✓ Input \"ctx\" has valid schema (type: entity.motion_context)",
                "Validating 1 output definition(s)",
                "  ✓ Output \"pose\" has valid schema (type: entity.motion_program)",
                "✓ Block has description: \"Thoughtful asymmetric pose with weight on one leg ...\""
              ],
              "inputCount": 2,
              "outputCount": 1,
              "hasDescription": true
            }
          }
        },
        {
          "id": "domain.validation",
          "label": "domain",
          "passed": true,
          "duration": 4215,
          "issues": [
            {
              "type": "warning",
              "code": "DOMAIN_SEMANTIC_ISSUE",
              "message": "Missing handling for optional bones in animations (e.g., rightUpperLeg, leftLowerLeg). Each movement should gracefully handle the absence of these bones to ensure robustness.",
              "file": "packages/motion-dsl/src/motions/contemplative-lean.ts"
            },
            {
              "type": "warning",
              "code": "DOMAIN_SEMANTIC_ISSUE",
              "message": "The overall performance requirement of updates completing in under 2ms needs verification. Current detailed computations may risk exceeding this limit, especially during multiple calculations per frame.",
              "file": "packages/motion-dsl/src/motions/contemplative-lean.ts"
            }
          ],
          "context": {
            "filesAnalyzed": [
              "contemplative-lean.ts"
            ],
            "rulesApplied": [],
            "philosophy": [
              "Motions must be anatomically accurate and biomechanically sound",
              "Every motion should utilize maximum bone engagement for realism",
              "Transitions between motions must be fluid and seamless",
              "Code must be deterministic - same seed produces same animation",
              "Movements should feel organic through layered animation and secondary motion",
              "All motions must gracefully handle missing optional bones",
              "Performance is critical - updates must complete in under 2ms",
              "Physics-based spring dynamics create natural acceleration curves",
              "Micro-movements and noise add life to static poses"
            ],
            "summary": "The block presents a well-structured motion for a contemplative pose but contains warnings regarding the handling of optional bones and potential performance issues that may violate domain requirements. Overall, while it adheres to the specified inputs and outputs, these areas require refinement for full compliance with the domain standards."
          },
          "ai": {
            "provider": "openai",
            "model": "gpt-4o-mini",
            "prompt": "Block Name: contemplative_lean\n\n\nBLOCKS PHILOSOPHY:\n- Motions must be anatomically accurate and biomechanically sound\n- Every motion should utilize maximum bone engagement for realism\n- Transitions between motions must be fluid and seamless\n- Code must be deterministic - same seed produces same animation\n- Movements should feel organic through layered animation and secondary motion\n- All motions must gracefully handle missing optional bones\n- Performance is critical - updates must complete in under 2ms\n- Physics-based spring dynamics create natural acceleration curves\n- Micro-movements and noise add life to static poses\n\nBlock Definition:\n{\n  \"description\": \"Thoughtful asymmetric pose with weight on one leg and thinking gestures\",\n  \"path\": \"packages/motion-dsl/src/motions/contemplative-lean.ts\",\n  \"inputs\": [\n    {\n      \"name\": \"rig\",\n      \"type\": \"entity.rig\"\n    },\n    {\n      \"name\": \"ctx\",\n      \"type\": \"entity.motion_context\"\n    }\n  ],\n  \"outputs\": [\n    {\n      \"name\": \"pose\",\n      \"type\": \"entity.motion_program\",\n      \"constraints\": [\n        \"Must implement asymmetric weight distribution\",\n        \"Must include hand-to-chin or crossed arms pose\",\n        \"Must animate all finger bones for detailed hand pose\",\n        \"Must include slow contemplative breathing\",\n        \"Must add subtle weight shift micro-movements\",\n        \"Should include thinking gestures (head tilt, eye movement)\",\n        \"Should support multiple pose variants via parameters\"\n      ]\n    }\n  ]\n}\n\n\nBLOCK FILES:\n\n--- contemplative-lean.ts ---\n```\n/**\n * Contemplative Lean Motion\n *\n * Thoughtful asymmetric pose with weight on one leg and thinking gestures.\n * Multiple pose variants including chin rest, crossed arms, and akimbo.\n *\n * Research basis:\n * - Thoughtful posture psychology\n * - Asymmetric stance biomechanics\n * - Self-touch gestures in contemplation\n * - Weight-bearing postural patterns\n */\n\nimport { z } from 'zod'\nimport type { MotionProgram, MotionMeta, HumanoidRig, MotionContext, VRMHumanBoneName } from '@posers/core'\nimport {\n  osc,\n  oscBreathing,\n  quatFromAxisAngle,\n  createNoiseGenerator,\n  createSpring,\n  Easing,\n  type NoiseGenerator,\n  type Spring,\n} from '@posers/core'\nimport {\n  BoneChains,\n  applyFingerCurl,\n} from '../blend'\n\n// ============================================================================\n// SCHEMA & TYPES\n// ============================================================================\n\nexport const contemplativeLeanParamsSchema = z.object({\n  /** Pose variant. Default: chin_rest */\n  poseVariant: z.enum(['chin_rest', 'crossed_arms', 'akimbo', 'hand_on_hip']).default('chin_rest'),\n  /** Intensity of thinking gestures (0-1). Default: 0.5 */\n  thoughtIntensity: z.number().min(0).max(1).default(0.5),\n  /** Depth of breathing (0-1). Default: 0.6 */\n  breathDepth: z.number().min(0).max(1).default(0.6),\n  /** Amount of subtle fidgeting (0-1). Default: 0.3 */\n  fidgetAmount: z.number().min(0).max(1).default(0.3),\n  /** Which leg bears weight. Default: right */\n  weightLeg: z.enum(['left', 'right']).default('right'),\n  /** Overall animation intensity (0-1). Default: 0.7 */\n  intensity: z.number().min(0).max(1).default(0.7),\n  /** Enable eye movement. Default: true */\n  eyeMovement: z.boolean().default(true),\n  /** Enable head tilts. Default: true */\n  headTilts: z.boolean().default(true),\n})\n\nexport type ContemplativeLeanParams = z.infer<typeof contemplativeLeanParamsSchema>\nexport type ContemplativeLeanInput = z.input<typeof contemplativeLeanParamsSchema>\n\nexport const contemplativeLeanMeta: MotionMeta = {\n  id: 'contemplative-lean',\n  name: 'Contemplative Lean',\n  description: 'Thoughtful asymmetric pose with weight on one leg and thinking gestures',\n  tags: ['contemplative', 'thinking', 'pose', 'idle'],\n  author: 'posers',\n}\n\n// ============================================================================\n// STATE MANAGEMENT\n// ============================================================================\n\ninterface ContemplativeLeanState {\n  noise: NoiseGenerator\n  weightSpring: Spring\n  headSpring: Spring\n  armSpring: Spring\n  blinkTimer: number\n  isBlinking: boolean\n  thinkingGestureTimer: number\n  currentGesture: 'idle' | 'head_tilt' | 'chin_tap' | 'look_away'\n  gestureDuration: number\n}\n\nfunction initState(seed: number): ContemplativeLeanState {\n  return {\n    noise: createNoiseGenerator(seed),\n    weightSpring: createSpring({ stiffness: 30, damping: 12 }),\n    headSpring: createSpring({ stiffness: 50, damping: 15 }),\n    armSpring: createSpring({ stiffness: 40, damping: 10 }),\n    blinkTimer: 0,\n    isBlinking: false,\n    thinkingGestureTimer: 0,\n    currentGesture: 'idle',\n    gestureDuration: 3,\n  }\n}\n\n// ============================================================================\n// POSE VARIANTS\n// ============================================================================\n\ninterface ArmPose {\n  leftUpperArm: { x: number; y: number; z: number }\n  leftLowerArm: { x: number; y: number; z: number }\n  leftHand: { x: number; y: number; z: number }\n  rightUpperArm: { x: number; y: number; z: number }\n  rightLowerArm: { x: number; y: number; z: number }\n  rightHand: { x: number; y: number; z: number }\n  leftFingers: { thumb: number; index: number; middle: number; ring: number; little: number }\n  rightFingers: { thumb: number; index: number; middle: number; ring: number; little: number }\n}\n\nfunction getArmPose(variant: string, intensity: number): ArmPose {\n  switch (variant) {\n    case 'chin_rest':\n      return {\n        // Right arm: hand to chin\n        rightUpperArm: { x: -0.8 * intensity, y: 0, z: -0.4 * intensity },\n        rightLowerArm: { x: 0, y: 1.3 * intensity, z: 0 },\n        rightHand: { x: 0.2 * intensity, y: 0, z: 0.1 * intensity },\n        // Left arm: support under right elbow\n        leftUpperArm: { x: 0.3 * intensity, y: 0, z: 0.25 * intensity },\n        leftLowerArm: { x: 0, y: -1.0 * intensity, z: 0 },\n        leftHand: { x: 0, y: 0, z: 0.15 * intensity },\n        // Fingers\n        rightFingers: { thumb: 0.2, index: 0.15, middle: 0.35, ring: 0.5, little: 0.55 },\n        leftFingers: { thumb: 0.3, index: 0.35, middle: 0.4, ring: 0.45, little: 0.5 },\n      }\n\n    case 'crossed_arms':\n      return {\n        rightUpperArm: { x: 0.5 * intensity, y: 0, z: -0.35 * intensity },\n        rightLowerArm: { x: 0, y: 1.4 * intensity, z: 0 },\n        rightHand: { x: 0, y: 0, z: -0.2 * intensity },\n        leftUpperArm: { x: 0.4 * intensity, y: 0, z: 0.25 * intensity },\n        leftLowerArm: { x: 0, y: -1.3 * intensity, z: 0 },\n        leftHand: { x: 0, y: 0, z: 0.15 * intensity },\n        rightFingers: { thumb: 0.2, index: 0.25, middle: 0.3, ring: 0.35, little: 0.4 },\n        leftFingers: { thumb: 0.25, index: 0.3, middle: 0.35, ring: 0.4, little: 0.45 },\n      }\n\n    case 'akimbo':\n      return {\n        rightUpperArm: { x: 0.15 * intensity, y: 0, z: -0.5 * intensity },\n        rightLowerArm: { x: 0, y: 1.4 * intensity, z: 0 },\n        rightHand: { x: -0.3 * intensity, y: 0, z: 0 },\n        leftUpperArm: { x: 0.15 * intensity, y: 0, z: 0.5 * intensity },\n        leftLowerArm: { x: 0, y: -1.4 * intensity, z: 0 },\n        leftHand: { x: -0.3 * intensity, y: 0, z: 0 },\n        rightFingers: { thumb: 0.1, index: 0.15, middle: 0.2, ring: 0.25, little: 0.3 },\n        leftFingers: { thumb: 0.1, index: 0.15, middle: 0.2, ring: 0.25, little: 0.3 },\n      }\n\n    case 'hand_on_hip':\n      return {\n        // Right hand on hip\n        rightUpperArm: { x: 0.2 * intensity, y: 0, z: -0.45 * intensity },\n        rightLowerArm: { x: 0, y: 1.3 * intensity, z: 0 },\n        rightHand: { x: -0.25 * intensity, y: 0, z: -0.1 * intensity },\n        // Left arm relaxed\n        leftUpperArm: { x: 0.05 * intensity, y: 0, z: 0.12 * intensity },\n        leftLowerArm: { x: 0, y: -0.15 * intensity, z: 0 },\n        leftHand: { x: 0, y: 0, z: 0.1 * intensity },\n        rightFingers: { thumb: 0.15, index: 0.2, middle: 0.25, ring: 0.3, little: 0.35 },\n        leftFingers: { thumb: 0.25, index: 0.3, middle: 0.35, ring: 0.4, little: 0.45 },\n      }\n\n    default:\n      return getArmPose('chin_rest', intensity)\n  }\n}\n\n// ============================================================================\n// MOTION IMPLEMENTATION\n// ============================================================================\n\nexport function createContemplativeLean(params: ContemplativeLeanInput = {}): MotionProgram<ContemplativeLeanParams> {\n  const validatedParams = contemplativeLeanParamsSchema.parse(params)\n  let state: ContemplativeLeanState | null = null\n\n  return {\n    meta: contemplativeLeanMeta,\n    paramsSchema: contemplativeLeanParamsSchema,\n\n    init(_rig: HumanoidRig, ctx: MotionContext): void {\n      state = initState(ctx.seed)\n    },\n\n    update(rig: HumanoidRig, ctx: MotionContext, t: number, dt: number): void {\n      if (!state) {\n        state = initState(ctx.seed)\n      }\n\n      const {\n        poseVariant,\n        thoughtIntensity,\n        breathDepth,\n        fidgetAmount,\n        weightLeg,\n        intensity,\n        eyeMovement,\n        headTilts,\n      } = validatedParams\n\n      const noise = state.noise\n      const isRightWeight = weightLeg === 'right'\n      const weightSide = isRightWeight ? 1 : -1\n\n      // ========================================\n      // THINKING GESTURE STATE MACHINE\n      // ========================================\n\n      state.thinkingGestureTimer += dt\n      if (state.thinkingGestureTimer > state.gestureDuration) {\n        state.thinkingGestureTimer = 0\n        state.gestureDuration = 2 + noise.noise2D(t, 50) * 3\n\n        // Pick next gesture\n        const gestureRoll = noise.noise2D(t, 100)\n        if (gestureRoll > 0.7 && headTilts) {\n          state.currentGesture = 'head_tilt'\n        } else if (gestureRoll > 0.4 && poseVariant === 'chin_rest') {\n          state.currentGesture = 'chin_tap'\n        } else if (gestureRoll > 0.2) {\n          state.currentGesture = 'look_away'\n        } else {\n          state.currentGesture = 'idle'\n        }\n      }\n\n      const gestureProgress = state.thinkingGestureTimer / state.gestureDuration\n      const gestureWeight = Math.sin(gestureProgress * Math.PI) * thoughtIntensity\n\n      // ========================================\n      // LAYER 1: ASYMMETRIC WEIGHT DISTRIBUTION\n      // ========================================\n\n      // Hip drop on non-weight-bearing side\n      const hipDrop = 0.06 * intensity * weightSide\n      const hipShift = 0.04 * intensity * weightSide\n\n      // Subtle weight shift noise\n      const weightNoise = noise.noise2D(t * 0.08, 200) * fidgetAmount * 0.02\n      state.weightSpring.setTarget(hipShift + weightNoise)\n      state.weightSpring.update(dt)\n\n      if (rig.hasBone('hips')) {\n        const hipsRot = quatFromAxisAngle({ x: 0, y: 0, z: 1 }, hipDrop + state.weightSpring.value)\n        hipsRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, weightSide * 0.03 * intensity))\n        rig.setRotation('hips', hipsRot)\n      }\n\n      // ========================================\n      // LAYER 2: SPINE (RELAXED, SLIGHT CURVE)\n      // ========================================\n\n      if (rig.hasBone('spine')) {\n        const spineRot = quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -hipDrop * 0.3)\n        spineRot.multiply(quatFromAxisAngle({ x: 1, y: 0, z: 0 }, 0.03 * intensity))\n        rig.setRotation('spine', spineRot)\n      }\n\n      if (rig.hasBone('chest')) {\n        const chestRot = quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -hipDrop * 0.2)\n        chestRot.multiply(quatFromAxisAngle({ x: 1, y: 0, z: 0 }, 0.02 * intensity))\n        rig.setRotation('chest', chestRot)\n      }\n\n      if (rig.hasBone('upperChest')) {\n        rig.setRotation('upperChest', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -hipDrop * 0.1))\n      }\n\n      // ========================================\n      // LAYER 3: DEEP CONTEMPLATIVE BREATHING\n      // ========================================\n\n      const breathPhase = oscBreathing(t, 0.12, breathDepth)\n\n      if (rig.hasBone('chest')) {\n        rig.addRotation('chest', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, breathPhase * 0.025))\n      }\n      if (rig.hasBone('upperChest')) {\n        rig.addRotation('upperChest', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, breathPhase * 0.035))\n      }\n\n      // Shoulder rise with breath\n      const shoulderBreath = breathPhase * 0.012\n      if (rig.hasBone('leftShoulder')) {\n        rig.setRotation('leftShoulder', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -shoulderBreath))\n      }\n      if (rig.hasBone('rightShoulder')) {\n        rig.setRotation('rightShoulder', quatFromAxisAngle({ x: 0, y: 0, z: 1 }, shoulderBreath))\n      }\n\n      // ========================================\n      // LAYER 4: LEGS (WEIGHT DISTRIBUTION)\n      // ========================================\n\n      // Weight-bearing leg: straight\n      // Non-weight leg: bent, relaxed\n\n      const weightLegBone = isRightWeight ? 'rightUpperLeg' : 'leftUpperLeg'\n      const relaxLegBone = isRightWeight ? 'leftUpperLeg' : 'rightUpperLeg'\n      const weightKnee = isRightWeight ? 'rightLowerLeg' : 'leftLowerLeg'\n      const relaxKnee = isRightWeight ? 'leftLowerLeg' : 'rightLowerLeg'\n      const weightFoot = isRightWeight ? 'rightFoot' : 'leftFoot'\n      const relaxFoot = isRightWeight ? 'leftFoot' : 'rightFoot'\n\n      if (rig.hasBone(weightLegBone as VRMHumanBoneName)) {\n        // Slight hip flexion on weight-bearing side\n        rig.setRotation(weightLegBone as VRMHumanBoneName,\n          quatFromAxisAngle({ x: 1, y: 0, z: 0 }, 0.02 * intensity))\n      }\n\n      if (rig.hasBone(relaxLegBone as VRMHumanBoneName)) {\n        // Relaxed leg forward and slightly bent\n        const relaxRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, 0.15 * intensity)\n        relaxRot.multiply(quatFromAxisAngle({ x: 0, y: 0, z: 1 }, -weightSide * 0.08 * intensity))\n        rig.setRotation(relaxLegBone as VRMHumanBoneName, relaxRot)\n      }\n\n      if (rig.hasBone(weightKnee as VRMHumanBoneName)) {\n        // Straight-ish weight-bearing knee\n        rig.setRotation(weightKnee as VRMHumanBoneName,\n          quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -0.03 * intensity))\n      }\n\n      if (rig.hasBone(relaxKnee as VRMHumanBoneName)) {\n        // Bent relaxed knee\n        rig.setRotation(relaxKnee as VRMHumanBoneName,\n          quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -0.2 * intensity))\n      }\n\n      // Feet\n      if (rig.hasBone(weightFoot as VRMHumanBoneName)) {\n        rig.setRotation(weightFoot as VRMHumanBoneName,\n          quatFromAxisAngle({ x: 0, y: 1, z: 0 }, weightSide * 0.08))\n      }\n\n      if (rig.hasBone(relaxFoot as VRMHumanBoneName)) {\n        // Relaxed foot on ball/toe\n        const relaxFootRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -0.15 * intensity)\n        relaxFootRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, -weightSide * 0.1))\n        rig.setRotation(relaxFoot as VRMHumanBoneName, relaxFootRot)\n      }\n\n      // Toes\n      const weightToes = isRightWeight ? 'rightToes' : 'leftToes'\n      const relaxToes = isRightWeight ? 'leftToes' : 'rightToes'\n\n      if (rig.hasBone(weightToes as VRMHumanBoneName)) {\n        rig.setRotation(weightToes as VRMHumanBoneName,\n          quatFromAxisAngle({ x: 1, y: 0, z: 0 }, 0.05))\n      }\n      if (rig.hasBone(relaxToes as VRMHumanBoneName)) {\n        rig.setRotation(relaxToes as VRMHumanBoneName,\n          quatFromAxisAngle({ x: 1, y: 0, z: 0 }, -0.1 * intensity))\n      }\n\n      // ========================================\n      // LAYER 5: ARMS (POSE VARIANT)\n      // ========================================\n\n      const armPose = getArmPose(poseVariant, intensity)\n\n      // Add subtle arm movement/fidget\n      const armFidget = noise.noise2D(t * 0.15, 300) * fidgetAmount * 0.02\n      state.armSpring.setTarget(armFidget)\n      state.armSpring.update(dt)\n      const armNoise = state.armSpring.value\n\n      if (rig.hasBone('leftUpperArm')) {\n        const rot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, armPose.leftUpperArm.x)\n        rot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, armPose.leftUpperArm.y + armNoise))\n        rot.multiply(quatFromAxisAngle({ x: 0, y: 0, z: 1 }, armPose.leftUpperArm.z))\n        rig.setRotation('leftUpperArm', rot)\n      }\n\n      if (rig.hasBone('leftLowerArm')) {\n        const rot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, armPose.leftLowerArm.x)\n        rot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, armPose.leftLowerArm.y))\n        rot.multiply(quatFromAxisAngle({ x: 0, y: 0, z: 1 }, armPose.leftLowerArm.z))\n        rig.setRotation('leftLowerArm', rot)\n      }\n\n      if (rig.hasBone('leftHand')) {\n        const rot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, armPose.leftHand.x)\n        rot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, armPose.leftHand.y))\n        rot.multiply(quatFromAxisAngle({ x: 0, y: 0, z: 1 }, armPose.leftHand.z))\n        rig.setRotation('leftHand', rot)\n      }\n\n      if (rig.hasBone('rightUpperArm')) {\n        const rot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, armPose.rightUpperArm.x)\n        rot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, armPose.rightUpperArm.y - armNoise))\n        rot.multiply(quatFromAxisAngle({ x: 0, y: 0, z: 1 }, armPose.rightUpperArm.z))\n        rig.setRotation('rightUpperArm', rot)\n      }\n\n      if (rig.hasBone('rightLowerArm')) {\n        // Add chin tap gesture for chin_rest variant\n        let chinTapAdd = 0\n        if (poseVariant === 'chin_rest' && state.currentGesture === 'chin_tap') {\n          chinTapAdd = Math.sin(state.thinkingGestureTimer * 6) * 0.05 * gestureWeight\n        }\n\n        const rot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, armPose.rightLowerArm.x)\n        rot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, armPose.rightLowerArm.y + chinTapAdd))\n        rot.multiply(quatFromAxisAngle({ x: 0, y: 0, z: 1 }, armPose.rightLowerArm.z))\n        rig.setRotation('rightLowerArm', rot)\n      }\n\n      if (rig.hasBone('rightHand')) {\n        const rot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, armPose.rightHand.x)\n        rot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, armPose.rightHand.y))\n        rot.multiply(quatFromAxisAngle({ x: 0, y: 0, z: 1 }, armPose.rightHand.z))\n        rig.setRotation('rightHand', rot)\n      }\n\n      // Fingers\n      applyFingerCurl(rig, 'left', armPose.leftFingers)\n      applyFingerCurl(rig, 'right', armPose.rightFingers)\n\n      // ========================================\n      // LAYER 6: HEAD & NECK (THINKING)\n      // ========================================\n\n      let headTiltX = 0.02 * intensity // Slight down\n      let headTiltY = 0\n      let headTiltZ = 0.03 * intensity * weightSide // Tilt toward weight side\n\n      // Add thinking gestures\n      if (state.currentGesture === 'head_tilt') {\n        headTiltZ += gestureWeight * 0.05 * (noise.noise2D(t, 400) > 0 ? 1 : -1)\n        headTiltX += gestureWeight * 0.03\n      } else if (state.currentGesture === 'look_away') {\n        headTiltY = gestureWeight * 0.1 * (noise.noise2D(t, 500) > 0 ? 1 : -1)\n      }\n\n      // Micro-movement\n      const headMicroX = noise.noise2D(t * 0.2, 600) * 0.01 * intensity\n      const headMicroY = noise.noise2D(t * 0.15, 700) * 0.015 * intensity\n\n      state.headSpring.setTarget(headTiltY + headMicroY)\n      state.headSpring.update(dt)\n\n      if (rig.hasBone('head')) {\n        const headRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, headTiltX + headMicroX)\n        headRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, state.headSpring.value))\n        headRot.multiply(quatFromAxisAngle({ x: 0, y: 0, z: 1 }, headTiltZ))\n        rig.setRotation('head', headRot)\n      }\n\n      if (rig.hasBone('neck')) {\n        const neckRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, headTiltX * 0.5)\n        neckRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, state.headSpring.value * 0.4))\n        neckRot.multiply(quatFromAxisAngle({ x: 0, y: 0, z: 1 }, headTiltZ * 0.3))\n        rig.setRotation('neck', neckRot)\n      }\n\n      // ========================================\n      // LAYER 7: EYES (CONTEMPLATIVE GAZE)\n      // ========================================\n\n      if (eyeMovement) {\n        // Slow, distant gaze with occasional focus shifts\n        let eyeX = 0\n        let eyeY = 0.02 * intensity // Slight downward gaze\n\n        if (state.currentGesture === 'look_away') {\n          eyeX = gestureWeight * 0.1 * (noise.noise2D(t, 800) > 0 ? 1 : -1)\n        } else {\n          eyeX = noise.noise2D(t * 0.1, 900) * 0.04 * intensity\n          eyeY += noise.noise2D(t * 0.08, 1000) * 0.02 * intensity\n        }\n\n        // Slow blinking (contemplative)\n        const blinkChance = noise.noise2D(t * 0.2, 1100)\n        if (!state.isBlinking && blinkChance > 0.92) {\n          state.isBlinking = true\n          state.blinkTimer = 0\n        }\n\n        let blinkAmount = 0\n        if (state.isBlinking) {\n          state.blinkTimer += dt\n          const blinkDuration = 0.2 // Slower, contemplative blink\n          if (state.blinkTimer > blinkDuration) {\n            state.isBlinking = false\n          } else {\n            blinkAmount = Math.sin(state.blinkTimer / blinkDuration * Math.PI) * 0.25\n          }\n        }\n\n        if (rig.hasBone('leftEye')) {\n          const leftEyeRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, eyeY - blinkAmount)\n          leftEyeRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, eyeX))\n          rig.setRotation('leftEye', leftEyeRot)\n        }\n\n        if (rig.hasBone('rightEye')) {\n          const rightEyeRot = quatFromAxisAngle({ x: 1, y: 0, z: 0 }, eyeY - blinkAmount)\n          rightEyeRot.multiply(quatFromAxisAngle({ x: 0, y: 1, z: 0 }, eyeX))\n          rig.setRotation('rightEye', rightEyeRot)\n        }\n      }\n\n      // ========================================\n      // LAYER 8: JAW (OCCASIONAL SUBTLE MOVEMENT)\n      // ========================================\n\n      if (rig.hasBone('jaw')) {\n        // Very subtle jaw movement as if thinking words\n        const jawThink = noise.noise2D(t * 0.3, 1200) > 0.85\n          ? noise.noise2D(t * 2, 1300) * 0.02 * thoughtIntensity\n          : 0\n        rig.setRotation('jaw', quatFromAxisAngle({ x: 1, y: 0, z: 0 }, jawThink))\n      }\n    },\n  }\n}\n\nexport const contemplativeLean: MotionProgram<ContemplativeLeanParams> = createContemplativeLean({})\n\n```\n\n\nVALIDATION TASK:\nAnalyze ALL files together to determine if this block:\n1. Expresses domain intent clearly in source code\n2. Uses specified inputs/outputs correctly\n3. Adheres to all domain rules\n4. For templates: Check if template SOURCE contains semantic HTML, ARIA labels, media queries, heading hierarchy\n5. Does NOT introduce undocumented concepts\n\nReturn validation issues with specific file references where possible.\nAlso provide a brief summary explaining why the block passed or failed validation.",
            "response": "{\n  \"isValid\": false,\n  \"issues\": [\n    {\n      \"message\": \"Missing handling for optional bones in animations (e.g., rightUpperLeg, leftLowerLeg). Each movement should gracefully handle the absence of these bones to ensure robustness.\",\n      \"severity\": \"warning\",\n      \"file\": \"packages/motion-dsl/src/motions/contemplative-lean.ts\"\n    },\n    {\n      \"message\": \"The overall performance requirement of updates completing in under 2ms needs verification. Current detailed computations may risk exceeding this limit, especially during multiple calculations per frame.\",\n      \"severity\": \"warning\",\n      \"file\": \"packages/motion-dsl/src/motions/contemplative-lean.ts\"\n    }\n  ],\n  \"summary\": \"The block presents a well-structured motion for a contemplative pose but contains warnings regarding the handling of optional bones and potential performance issues that may violate domain requirements. Overall, while it adheres to the specified inputs and outputs, these areas require refinement for full compliance with the domain standards.\"\n}",
            "tokensUsed": {
              "input": 6906,
              "output": 181
            }
          }
        }
      ],
      "cache": {
        "decision": "Force mode: running all validators",
        "skippedValidators": 0,
        "revalidationReason": "force_flag"
      }
    }
  ]
}